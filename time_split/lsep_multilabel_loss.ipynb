{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jp\n",
    "from scipy import sparse\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook \n",
    "\n",
    "from jax import random\n",
    "from jax.experimental import stax,optimizers\n",
    "from jax.experimental.stax import Dense\n",
    "from jax import grad, value_and_grad, vmap\n",
    "from jax.nn.initializers import he_uniform, glorot_normal\n",
    "from jax.experimental.stax import Dense, Relu, LeakyRelu, Elu, Dropout, Gelu, Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_matrix = sparse.load_npz('../data/interaction_matrix_pchembl.npz')\n",
    "##interaction_matrix = np.array(interaction_matrix.todense())\n",
    "#\n",
    "interaction_dates = sparse.load_npz('../data/interaction_dates_pchembl.npz')\n",
    "##interaction_dates = np.array(interaction_dates.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "year=2010\n",
    "#turn interaction dates into a masker\n",
    "dates_mask = (interaction_dates.data<=year).astype(int)\n",
    "\n",
    "\n",
    "#make copies that will become train / test matrices\n",
    "train = copy.copy(interaction_matrix)\n",
    "test = copy.copy(interaction_matrix)\n",
    "\n",
    "#remove 2015 and later records from train matrix\n",
    "train.data = train.data * dates_mask\n",
    "#remove all training data from the test matrix.\n",
    "test.data = test.data - train.data\n",
    "\n",
    "#remove any rows from the train matrix that have zero interactions.\n",
    "#this is the case any time a new ligand is discovered in the cutoff-year or after.\n",
    "#we can't use link prediction on new ligands! It's a cold start problem.\n",
    "#so we remove all these ligands from the present analysis.\n",
    "row_mask = np.array((train.sum(axis=1)!=0)).reshape(1,-1)[0] #there must be a cleaner way to do that.\n",
    "train = train[row_mask]\n",
    "test = test[row_mask]\n",
    "\n",
    "train.eliminate_zeros()\n",
    "test.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_my_network():\n",
    "    test_rng = random.PRNGKey(1)\n",
    "    _, dec_init_rng = random.split(random.PRNGKey(2))\n",
    "    ##got median down to about 15 or 16 using glorot_normal and no activations. 3x243.\n",
    "    #and that had adam optimizer with step_size=1e-4. \n",
    "    #243, 125, 243 also works pretty good, with glorot_normal.\n",
    "    decoder_init, decode = stax.serial(\n",
    "        Dense(243, W_init=glorot_normal()), \n",
    "        #Dense(125, W_init=glorot_normal()), \n",
    "        #Dense(243, W_init=glorot_normal()),\n",
    "        #Dense(243, W_init=glorot_normal()),\n",
    "        Dense(243, W_init=glorot_normal()),\n",
    "        Dense(243, W_init=glorot_normal()),\n",
    "        Sigmoid)\n",
    "\n",
    "    _, init_decoder_params =decoder_init(dec_init_rng, (-1,243))\n",
    "    opt_init, opt_update, get_params = optimizers.adam(step_size=1e-4)\n",
    "    #opt_init, opt_update, get_params = optimizers.adagrad(step_size=1e-3)\n",
    "    opt_state = opt_init(init_decoder_params)\n",
    "    return opt_state, opt_update, decode, get_params\n",
    "\n",
    "def compare_ranks(score, lab):\n",
    "    return (jp.log(1+jp.exp(score-score[:,jp.newaxis]))*lab).sum()\n",
    "\n",
    "\n",
    "def loss(p, label_vector):\n",
    "    scores = decode(p,label_vector)\n",
    "    #label_mask = label_vector.astype(bool)\n",
    "    #scores_pos = scores[label_mask]\n",
    "    #scores_neg = scores[~label_mask]\n",
    "    #cores_diff = scores_neg-scores_pos[:,jp.newaxis]\n",
    "    \n",
    "    return - vmap(compare_ranks, in_axes=(0,0))(scores, label_vector).sum()\n",
    "\n",
    "\n",
    "def step(i, opt_state):\n",
    "    p = get_params(opt_state)  \n",
    "    #a random input:\n",
    "    label_vector = mymat[np.random.choice(np.arange(mymat.shape[0]), 200, replace=False)]\n",
    "    l, g = value_and_grad(loss)(p, label_vector)\n",
    "    \n",
    "    if i%10==0:\n",
    "        loss_list.append(l)\n",
    "        print(l)\n",
    "    #if i%10==0:\n",
    "    #    print('PRINTING RESULT ON TEST:')\n",
    "        #preds = decode(p, train.toarray())\n",
    "        #ranks = evaluate_predictions(preds, test, train )\n",
    "        #ranks_median_list.append(np.median(ranks))\n",
    "        #ranks_mean_list.append(np.mean(ranks))\n",
    "        #print(np.median(ranks), np.mean(ranks))\n",
    "        #doplot(ranks_median_list, ranks_mean_list)\n",
    "        \n",
    "    return opt_update(i, g, opt_state)\n",
    "\n",
    "def doplot(medians, means):\n",
    "    fig,ax=plt.subplots()\n",
    "    ax.plot(medians, label='medians')\n",
    "    ax.plot(means, label='means')\n",
    "    ax.legend()\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(10,150)\n",
    "    ax.set_yticks([10,20,30,40,50,60,70,80,90,100,150])\n",
    "    fig.savefig('progress.png')\n",
    "    plt.close()\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymat = train.toarray()#interaction_matrix.toarray()\n",
    "\n",
    "row_mask = mymat.sum(axis=1)>1\n",
    "\n",
    "mymat = mymat[row_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmar3213/miniconda3/envs/lew_jax/lib/python3.8/site-packages/jax/lib/xla_bridge.py:120: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n",
      "<ipython-input-9-549bd4ca5898>:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(2860)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6585e3f1954946c2a1d8ca63a4e54dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2860.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-96503.32\n",
      "-89295.11\n",
      "-108139.78\n",
      "-92888.516\n",
      "-104890.195\n",
      "-106273.195\n",
      "-107995.76\n",
      "-100372.08\n",
      "-102821.23\n",
      "-108879.586\n",
      "-103228.68\n",
      "-101996.086\n",
      "-108913.74\n",
      "-110145.81\n",
      "-107947.48\n",
      "-108085.87\n",
      "-109043.08\n",
      "-118570.266\n",
      "-131095.6\n",
      "-131810.52\n",
      "-128538.71\n",
      "-129122.39\n",
      "-119442.17\n",
      "-140292.92\n",
      "-131925.34\n",
      "-137884.39\n",
      "-142146.19\n",
      "-151242.98\n",
      "-141330.97\n",
      "-148331.03\n",
      "-144481.55\n",
      "-143211.45\n",
      "-144792.97\n",
      "-140190.81\n",
      "-157402.84\n",
      "-135990.7\n",
      "-148655.94\n",
      "-147690.86\n",
      "-154587.38\n",
      "-143341.4\n",
      "-141532.97\n",
      "-147982.14\n",
      "-172250.25\n",
      "-155055.66\n",
      "-147987.78\n",
      "-159168.67\n",
      "-153725.1\n",
      "-147003.78\n",
      "-143998.38\n",
      "-161767.72\n",
      "-171117.66\n",
      "-140506.48\n",
      "-154647.34\n",
      "-162389.19\n",
      "-150162.03\n",
      "-167295.6\n",
      "-174159.3\n",
      "-149419.9\n",
      "-154020.23\n",
      "-149884.89\n",
      "-165954.05\n",
      "-148494.97\n",
      "-168574.94\n",
      "-152176.7\n",
      "-159063.66\n",
      "-152620.77\n",
      "-158244.97\n",
      "-156753.22\n",
      "-163635.62\n",
      "-160699.27\n",
      "-163590.64\n",
      "-144586.73\n",
      "-161819.98\n",
      "-157393.31\n",
      "-171754.98\n",
      "-171053.72\n",
      "-164082.81\n",
      "-157257.88\n",
      "-182222.42\n",
      "-164117.64\n",
      "-157034.78\n",
      "-168405.03\n",
      "-165771.47\n",
      "-152195.97\n",
      "-166845.16\n",
      "-168804.05\n",
      "-174844.78\n",
      "-167918.83\n",
      "-165011.44\n",
      "-153368.92\n",
      "-174363.42\n",
      "-171069.64\n",
      "-160582.75\n",
      "-159129.44\n",
      "-170069.08\n",
      "-162920.64\n",
      "-170264.77\n",
      "-180231.45\n",
      "-154262.66\n",
      "-183999.16\n",
      "-163403.58\n",
      "-178163.62\n",
      "-168879.72\n",
      "-167156.27\n",
      "-170598.19\n",
      "-172644.9\n",
      "-168541.89\n",
      "-168239.98\n",
      "-164101.0\n",
      "-211581.12\n",
      "-170024.64\n",
      "-167038.3\n",
      "-172147.52\n",
      "-160584.4\n",
      "-156339.61\n",
      "-161777.75\n",
      "-165588.27\n",
      "-173100.47\n",
      "-167898.05\n",
      "-170055.9\n",
      "-167124.9\n",
      "-175475.1\n",
      "-167665.92\n",
      "-174782.66\n",
      "-187560.86\n",
      "-156256.36\n",
      "-168019.47\n",
      "-178983.64\n",
      "-175475.03\n",
      "-163782.19\n",
      "-168547.53\n",
      "-175574.28\n",
      "-158853.3\n",
      "-157624.58\n",
      "-184475.62\n",
      "-166273.75\n",
      "-178212.03\n",
      "-166068.03\n",
      "-162126.6\n",
      "-183796.78\n",
      "-175742.48\n",
      "-162058.12\n",
      "-171696.92\n",
      "-160225.84\n",
      "-178187.33\n",
      "-170480.23\n",
      "-167963.97\n",
      "-176149.2\n",
      "-166568.56\n",
      "-165888.3\n",
      "-162047.47\n",
      "-173125.25\n",
      "-166673.44\n",
      "-164286.45\n",
      "-166591.6\n",
      "-161439.11\n",
      "-174530.6\n",
      "-163220.34\n",
      "-169048.06\n",
      "-164464.53\n",
      "-158261.89\n",
      "-161312.23\n",
      "-179767.22\n",
      "-164559.83\n",
      "-175994.5\n",
      "-167091.86\n",
      "-174739.88\n",
      "-175643.73\n",
      "-169958.05\n",
      "-158631.95\n",
      "-160748.56\n",
      "-166722.81\n",
      "-172706.92\n",
      "-172099.56\n",
      "-167092.23\n",
      "-174554.86\n",
      "-169807.77\n",
      "-200025.44\n",
      "-172138.48\n",
      "-172369.0\n",
      "-170191.28\n",
      "-161364.75\n",
      "-165372.5\n",
      "-164518.88\n",
      "-172996.89\n",
      "-204660.28\n",
      "-159085.83\n",
      "-166016.64\n",
      "-175033.06\n",
      "-176399.7\n",
      "-190041.1\n",
      "-158805.69\n",
      "-161015.02\n",
      "-164609.19\n",
      "-173558.6\n",
      "-164584.16\n",
      "-170328.28\n",
      "-165710.17\n",
      "-156743.48\n",
      "-176117.5\n",
      "-168967.72\n",
      "-175376.11\n",
      "-179172.83\n",
      "-174632.33\n",
      "-159326.55\n",
      "-171292.73\n",
      "-180036.1\n",
      "-163132.64\n",
      "-173200.12\n",
      "-180220.75\n",
      "-162215.78\n",
      "-179134.02\n",
      "-170197.02\n",
      "-172680.55\n",
      "-179551.69\n",
      "-165264.55\n",
      "-155836.42\n",
      "-167703.16\n",
      "-161263.6\n",
      "-177268.64\n",
      "-175918.92\n",
      "-163894.52\n",
      "-169854.9\n",
      "-174994.42\n",
      "-178207.98\n",
      "-164748.77\n",
      "-174686.8\n",
      "-166552.45\n",
      "-164027.7\n",
      "-170954.94\n",
      "-157584.03\n",
      "-160726.62\n",
      "-174709.31\n",
      "-178882.95\n",
      "-170774.67\n",
      "-168543.64\n",
      "-183715.3\n",
      "-168049.77\n",
      "-153480.8\n",
      "-175729.77\n",
      "-183011.27\n",
      "-169720.86\n",
      "-166578.22\n",
      "-184791.9\n",
      "-172440.62\n",
      "-161779.42\n",
      "-159676.31\n",
      "-170697.72\n",
      "-169896.03\n",
      "-176880.81\n",
      "-166730.89\n",
      "-167768.06\n",
      "-178322.0\n",
      "-163683.36\n",
      "-163339.72\n",
      "-193242.44\n",
      "-169522.48\n",
      "-180494.81\n",
      "-207123.44\n",
      "-170956.08\n",
      "-185078.12\n",
      "-175389.66\n",
      "-168111.47\n",
      "-168096.23\n",
      "-176471.16\n",
      "-169635.45\n",
      "-175590.55\n",
      "-174763.28\n",
      "-161128.62\n",
      "-179097.55\n",
      "-173253.44\n",
      "-188246.03\n",
      "-198780.72\n",
      "-167665.47\n",
      "-166256.2\n",
      "-193516.25\n",
      "-175993.6\n",
      "-170743.62\n",
      "-170271.03\n",
      "-173491.25\n",
      "-188484.17\n",
      "-171082.28\n",
      "-180973.97\n",
      "-163448.64\n",
      "-168170.56\n",
      "-160777.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_list = list()\n",
    "ranks_median_list = list()\n",
    "ranks_mean_list = list()\n",
    "opt_state, opt_update, decode, get_params = init_my_network()\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm_notebook(range(2860)):\n",
    "    opt_state = step(i, opt_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import rankdata\n",
    "def evaluate_predictions(predictions, test, train):\n",
    "    \"\"\"\n",
    "    Input a numpy array, with rows for instances and columns for labels,\n",
    "    with entries containing predicted interaction scores. Usually, the higher\n",
    "    the highest interaction score corresponds to the top predicted ligand,\n",
    "    and thus function assumes the most positive score is the best.\n",
    "\n",
    "    Calculates the ranks of the test ligands and returns the mean rank.\n",
    "    This is to be optimized (i.e. minimized) by scikit-optimize.\n",
    "\n",
    "    :param prediction_matrix: n by m np array (n = number of instances, m = number of labels)\n",
    "    containg predicted interaction scores resulting from some recommender algorithm\n",
    "    :param test: n by m sparse matrix containing 1's in the positions of each test label. Returned\n",
    "    by train_test_split.\n",
    "#    :param outtype: either 'mean', 'unbiased_mean', or 'full'. Mean gives the mean over\n",
    "#    all ranks for each test label. Unbiased mean accounts for inspection bias (where promiscuous\n",
    "#    ligands are over-represented in the mean statistic) by first taking the mean rank for EACH\n",
    "#    ligand, and then taking mean over all these. 'Full' just returns the ranks of all ligands.\n",
    "    \"\"\"\n",
    "    if isinstance(test, sparse.csr_matrix):\n",
    "        test = test.toarray()\n",
    "    if isinstance(train, sparse.csr_matrix):\n",
    "        train = train.toarray()\n",
    "    if isinstance(predictions, sparse.csr_matrix):\n",
    "        predictions = predictions.toarray()\n",
    "        \n",
    "    #This will mask all ROWS that contain no test ligands. No point ranking\n",
    "    #a row if you're aren't going to evaluate the ranks!\n",
    "    #(and it works on sparse or np.array)\n",
    "    row_mask = np.array(test.sum(axis=1)>0).reshape(-1,)\n",
    "    test_masked = test[row_mask]\n",
    "    get_ranks = test_masked.astype(bool) #this will select using boolean all test ranks.\n",
    "\n",
    "    ####Double argsort approach (not used anymore):\n",
    "    ##order from highest to lowest:\n",
    "    #order = (-prediction_matrix).argsort(axis=1)\n",
    "    ##get ranks of each ligand.\n",
    "    #ranks = order.argsort(axis=1)\n",
    "\n",
    "    #This step masks the known positives from the training set,\n",
    "    #so we are not penalising a highly ranked unknown if it\n",
    "    #is only behind other true positives. This has a pretty substantial\n",
    "    #effect since the algo's are really good at ranking known positives highly.\n",
    "    predictions = np.ma.masked_array(predictions[row_mask], mask=train[row_mask].astype(bool))\n",
    "    #rankdata approach, which correctly handles ties and also thankgod can take masked arrays:\n",
    "    prediction_ranks = rankdata(-predictions, axis=1)\n",
    "\n",
    "    #all ranks:\n",
    "    all_test_ranks = prediction_ranks[get_ranks]\n",
    "    return all_test_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = get_params(opt_state)  \n",
    "preds = decode(p, train.toarray())\n",
    "ranks = evaluate_predictions(preds, test, train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('jax-ranks.npy', ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x10db17220>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD6CAYAAABJTke4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAR30lEQVR4nO3db4xVeX3H8fdHVmmrNoI7EAqksA21ZZv4JxPU2BjrVhe1kW3STTGpIc02+AAbTdpUqA9qH5CsTWrqg64pVVvSWin1T5aosVLqxjQx4qyuuixSRnddRiiMGuOfJtjFbx/MWb2yM8yd+4eB+b1fCTnn/O7vnPv9cS6fe+655x5SVUiS2vK05S5AknT9Gf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ1aNPyTPC/JQz1/vpfkrUnWJjme5Gw3XdOzzoEk00nOJLlzvEOQJC1VlnKdf5JVwDeBFwP7gO9U1b1J9gNrquptSbYDHwR2AL8E/Afwq1V1ZaHt3nrrrbVly5bBRzGEr8/+EIDbJp65LM8vSYN68MEHv1VVE4Ose8sS+98BfK2qvpFkF/CKrv0w8ADwNmAXcKSqLgOPJplm7o3gswttdMuWLUxNTS2xlNH4/b+bK+tf3/TSZXl+SRpUkm8Muu5Sz/nvZu6oHmB9VV0A6KbruvaNwLmedWa6NknSDaLv8E/yDOD1wL8t1nWetqecW0qyN8lUkqnZ2dl+y5AkjcBSjvxfA3yhqi52yxeTbADoppe69hlgc896m4DzV2+sqg5V1WRVTU5MDHTKSpI0oKWE/xv46SkfgGPAnm5+D3B/T/vuJKuTbAW2ASeHLVSSNDp9feGb5BeAVwFv6mm+Fzia5B7gceBugKo6leQo8AjwBLDvWlf6SJKuv77Cv6r+F3juVW3fZu7qn/n6HwQODl2dJGks/IWvJDXI8JekBhn+ktSgpf7C94a0Zf/HfzL/2L2vW8ZKJOnm4JG/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QG9RX+SZ6T5ENJvprkdJKXJlmb5HiSs910TU//A0mmk5xJcuf4ypckDaLfI/93A5+sql8Dng+cBvYDJ6pqG3CiWybJdmA3cDuwE7gvyapRFy5JGtyi4Z/kF4GXA+8DqKofVdV3gV3A4a7bYeCubn4XcKSqLlfVo8A0sGPUhUuSBtfPkf9twCzwD0m+mOS9SZ4JrK+qCwDddF3XfyNwrmf9ma7tZyTZm2QqydTs7OxQg5AkLU0/4X8L8CLgPVX1QuCHdKd4FpB52uopDVWHqmqyqiYnJib6KlaSNBr9hP8MMFNVn+uWP8Tcm8HFJBsAuumlnv6be9bfBJwfTbmSpFFYNPyr6n+Ac0me1zXdATwCHAP2dG17gPu7+WPA7iSrk2wFtgEnR1q1JGkot/TZ74+BDyR5BvB14A+Ze+M4muQe4HHgboCqOpXkKHNvEE8A+6rqysgrlyQNrK/wr6qHgMl5Hrpjgf4HgYND1CVJGiN/4StJDTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhrUV/gneSzJV5I8lGSqa1ub5HiSs910TU//A0mmk5xJcue4ipckDWYpR/6/VVUvqKrJbnk/cKKqtgEnumWSbAd2A7cDO4H7kqwaYc2SpCENc9pnF3C4mz8M3NXTfqSqLlfVo8A0sGOI55EkjVi/4V/Ap5I8mGRv17a+qi4AdNN1XftG4FzPujNd289IsjfJVJKp2dnZwaqXJA3klj77vayqzidZBxxP8tVr9M08bfWUhqpDwCGAycnJpzwuSRqfvo78q+p8N70EfJS50zgXk2wA6KaXuu4zwOae1TcB50dVsCRpeIuGf5JnJnn2k/PAq4GHgWPAnq7bHuD+bv4YsDvJ6iRbgW3AyVEXLkkaXD+nfdYDH03yZP9/qapPJvk8cDTJPcDjwN0AVXUqyVHgEeAJYF9VXRlL9ZKkgSwa/lX1deD587R/G7hjgXUOAgeHrk6SNBb+wleSGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQX2Hf5JVSb6Y5GPd8tokx5Oc7aZrevoeSDKd5EySO8dRuCRpcEs58n8LcLpneT9woqq2ASe6ZZJsB3YDtwM7gfuSrBpNuZKkUegr/JNsAl4HvLeneRdwuJs/DNzV036kqi5X1aPANLBjNOVKkkah3yP/vwH+DPhxT9v6qroA0E3Xde0bgXM9/Wa6NknSDWLR8E/yO8Clqnqwz21mnraaZ7t7k0wlmZqdne1z05KkUejnyP9lwOuTPAYcAV6Z5J+Bi0k2AHTTS13/GWBzz/qbgPNXb7SqDlXVZFVNTkxMDDEESdJSLRr+VXWgqjZV1Rbmvsj9z6r6A+AYsKfrtge4v5s/BuxOsjrJVmAbcHLklUuSBnbLEOveCxxNcg/wOHA3QFWdSnIUeAR4AthXVVeGrlSSNDJLCv+qegB4oJv/NnDHAv0OAgeHrE2SNCb+wleSGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDVo0fBP8nNJTib5UpJTSf6ya1+b5HiSs910Tc86B5JMJzmT5M5xDkCStHT9HPlfBl5ZVc8HXgDsTPISYD9woqq2ASe6ZZJsB3YDtwM7gfuSrBpH8ZKkwSwa/jXnB93i07s/BewCDnfth4G7uvldwJGqulxVjwLTwI6RVi1JGkpf5/yTrEryEHAJOF5VnwPWV9UFgG66ruu+ETjXs/pM1yZJukH0Ff5VdaWqXgBsAnYk+Y1rdM98m3hKp2RvkqkkU7Ozs/1VK0kaiSVd7VNV3wUeYO5c/sUkGwC66aWu2wywuWe1TcD5ebZ1qKomq2pyYmJigNIlSYPq52qfiSTP6eZ/Hvht4KvAMWBP120PcH83fwzYnWR1kq3ANuDkqAuXJA3ulj76bAAOd1fsPA04WlUfS/JZ4GiSe4DHgbsBqupUkqPAI8ATwL6qujKe8iVJg1g0/Kvqy8AL52n/NnDHAuscBA4OXZ0kaSz8ha8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWrQouGfZHOSTyc5neRUkrd07WuTHE9ytpuu6VnnQJLpJGeS3DnOAUiSlq6fI/8ngD+pql8HXgLsS7Id2A+cqKptwIlume6x3cDtwE7gviSrxlG8JGkwtyzWoaouABe6+e8nOQ1sBHYBr+i6HQYeAN7WtR+pqsvAo0mmgR3AZ0dd/Hy27P/4T+Yfu/d11+MpJemms6Rz/km2AC8EPges794YnnyDWNd12wic61ltpmu7elt7k0wlmZqdnV165ZKkgfUd/kmeBXwYeGtVfe9aXedpq6c0VB2qqsmqmpyYmOi3DEnSCPQV/kmezlzwf6CqPtI1X0yyoXt8A3Cpa58BNvesvgk4P5pyJUmj0M/VPgHeB5yuqnf1PHQM2NPN7wHu72nfnWR1kq3ANuDk6EqWJA1r0S98gZcBbwS+kuShru3PgXuBo0nuAR4H7gaoqlNJjgKPMHel0L6qujLyyiVJA+vnap//Yv7z+AB3LLDOQeDgEHVJksbIX/hKUoMMf0lqkOEvSQ0y/CWpQf1c7XPT8lYPkjQ/j/wlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1KAVfWO3Xt7kTZJ+yiN/SWqQ4S9JDTL8JalBhr8kNWjR8E/y/iSXkjzc07Y2yfEkZ7vpmp7HDiSZTnImyZ3jKlySNLh+jvz/Edh5Vdt+4ERVbQNOdMsk2Q7sBm7v1rkvyaqRVStJGolFw7+qPgN856rmXcDhbv4wcFdP+5GqulxVjwLTwI4R1SpJGpFBz/mvr6oLAN10Xde+ETjX02+ma3uKJHuTTCWZmp2dHbAMSdIgRv2Fb+Zpq/k6VtWhqpqsqsmJiYkRlyFJupZBw/9ikg0A3fRS1z4DbO7ptwk4P3h5kqRxGDT8jwF7uvk9wP097buTrE6yFdgGnByuREnSqC16b58kHwReAdyaZAb4C+Be4GiSe4DHgbsBqupUkqPAI8ATwL6qujKm2iVJA1o0/KvqDQs8dMcC/Q8CB4cpSpI0Xv7CV5Ia1MwtnXv13t65t81bPUtqRZPh349+7v/v/xEg6WblaR9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhrkdf495vvxlyStRB75S1KDDH9JapCnfZbIU0Mri7foUKsM/z4Y+JJWGsN/RPp5g/DIUtKNwnP+ktQgj/yvI88vrywLfdpz3+pmYPgvk1G9EVwdQAaPpH4Y/jcwjyzVAj8RLw/D/wYwrquJWvjfyK7HG+Qwf0fj+IR3M+4n3XjGFv5JdgLvBlYB762qe8f1XPqphcLwRgiPVj7JXM9Lg4fdrzfC60LLYyzhn2QV8LfAq4AZ4PNJjlXVI+N4vtZcj08KS3U9j2r7qfNa34X08wY5bkv9VDaO7S+nQfbhfJZzbDf63/FixnXkvwOYrqqvAyQ5AuwCDP8bwDhCbqF/CKMKsGGNalvj/rsbpv+wb2pLDdsb4bTiUl93/dYwzPo3yyfcVNXoN5r8HrCzqv6oW34j8OKqevN8/ScnJ2tqamrg5/MXuJKuh2EObJb6xtmPJA9W1eQg647ryD/ztP3Mu0ySvcDebvEHSc4M8Dy3At8aYL2VwvE7fsd/HeWdo193iG3eCvzyoCuPK/xngM09y5uA870dquoQcGiYJ0kyNei73krg+B2/429+/FsGXX9ct3f4PLAtydYkzwB2A8fG9FySpCUay5F/VT2R5M3AvzN3qef7q+rUOJ5LkrR0Y7vOv6o+AXxiXNvvDHXaaAVw/G1z/G0b7rT5OK72kSTd2LylsyQ16KYN/yQ7k5xJMp1k/3LXcz0keSzJV5I8lGSqa1ub5HiSs910zXLXOSpJ3p/kUpKHe9oWHG+SA93r4UySO5en6tFZYPzvSPLN7jXwUJLX9jy2YsafZHOSTyc5neRUkrd07U3s/2uMf3T7v6puuj/MfYn8NeA24BnAl4Dty13XdRj3Y8CtV7X9FbC/m98PvHO56xzheF8OvAh4eLHxAtu718FqYGv3+li13GMYw/jfAfzpPH1X1PiBDcCLuvlnA//djbGJ/X+N8Y9s/9+sR/4/uX1EVf0IePL2ES3aBRzu5g8Ddy1jLSNVVZ8BvnNV80Lj3QUcqarLVfUoMM3c6+SmtcD4F7Kixl9VF6rqC93894HTwEYa2f/XGP9Cljz+mzX8NwLnepZnuPZfzEpRwKeSPNj9QhpgfVVdgLkXDLBu2aq7PhYab0uviTcn+XJ3WujJ0x4rdvxJtgAvBD5Hg/v/qvHDiPb/zRr+i94+YoV6WVW9CHgNsC/Jy5e7oBtIK6+J9wC/ArwAuAD8dde+Isef5FnAh4G3VtX3rtV1nraVOP6R7f+bNfwXvX3ESlRV57vpJeCjzH2su5hkA0A3vbR8FV4XC423iddEVV2sqitV9WPg7/npR/sVN/4kT2cu+D5QVR/pmpvZ//ONf5T7/2YN/+ZuH5HkmUme/eQ88GrgYebGvafrtge4f3kqvG4WGu8xYHeS1Um2AtuAk8tQ31g9GXyd32XuNQArbPxJArwPOF1V7+p5qIn9v9D4R7r/l/tb7SG+DX8tc9+Afw14+3LXcx3Gextz3+Z/CTj15JiB5wIngLPddO1y1zrCMX+QuY+2/8fckc091xov8Pbu9XAGeM1y1z+m8f8T8BXgy90/+A0rcfzAbzJ32uLLwEPdn9e2sv+vMf6R7X9/4StJDbpZT/tIkoZg+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1KD/B4td8nMLncTZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_=plt.hist(ranks,bins=100)\n",
    "plt.axvline(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ranks_median_list)\n",
    "plt.plot(ranks_mean_list)\n",
    "plt.axvline(np.argmin(ranks_mean_list))\n",
    "plt.axvline(np.argmin(ranks_median_list))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ranks_mean_list)):\n",
    "    if ranks_mean_list[i+1] > ranks_mean_list[i]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(ranks_median_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ranks_median_list, ranks_mean_list)\n",
    "plt.ylim(40,60)\n",
    "plt.xlim(0,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = get_params(opt_state)\n",
    "\n",
    "label_vector = mymat[np.random.choice(np.arange(mymat.shape[0]), 10, replace=False)]\n",
    "\n",
    "\n",
    "#scores = jp.log(decode(p,label_vector))\n",
    "#l, g = value_and_grad(loss)(p, label_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = decode(p, train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_=plt.hist(evaluate_predictions(preds, test, train ),bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(evaluate_predictions(preds, test, train ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boop[88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[0]*(1-label_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.log(raw)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vmap(compare_ranks, in_axes=(0,0))(scores, label_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_ranks(scores[0], label_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_ranks(score, lab):\n",
    "    return (jp.log(1+jp.exp(score-score[:,jp.newaxis]))*lab).sum()\n",
    "    \n",
    "    #score_pos = score*lab\n",
    "    #score_neg = score*(1-lab)\n",
    "    #score_diff = score_pos[:,jp.newaxis] - score_neg\n",
    "    return score_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vmap(compare_ranks,in_axes=(0,0))(scores, label_vector.astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vector.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(jp.log(1+jp.exp(score-score[:,jp.newaxis])) * lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(score_pos[:,jp.newaxis] - score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_ranks(scores[0], mymat[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vmapped = vmap(compare_ranks, in_axes=(0,0))\n",
    "\n",
    "vmapped(scores, label_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp.array(label_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = jp.log(decode(p,label_vector))\n",
    "label_mask = label_vector.astype(bool)\n",
    "scores_pos = scores[label_mask]\n",
    "scores_neg = scores[~label_mask]\n",
    "    \n",
    "scores_diff = scores_neg-scores_pos[:,jp.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[label_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(label_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vector[0].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[0][232]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = get_params(opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymat = interaction_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(np.arange(243))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
