{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmar3213/miniconda3/envs/lew_conda/lib/python3.7/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from tqdm import tqdm_notebook\n",
    "from seaborn import kdeplot\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_matrix = sparse.load_npz('../data/interaction_matrix_pchembl.npz')\n",
    "##interaction_matrix = np.array(interaction_matrix.todense())\n",
    "#\n",
    "interaction_dates = sparse.load_npz('../data/interaction_dates_pchembl.npz')\n",
    "##interaction_dates = np.array(interaction_dates.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The publication dates of the interactions are recorded in ChEMBL. Looking below we can see the distribution of years: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x112a87250>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXyU1b348c93tkz2kI2EsCQoq6CoCLjUDRdQC7a3/VVtq9bbUn9Xa+3iT+nttdb7+7W2Wq9arVyv1UprxbrUYkVFrAtWlB1ZAwFZQvZA9kwmkzm/P2YShpCQSTLJbN/36zWvzDzPeZ75ziF8c+Y85zlHjDEopZSKfZZwB6CUUmp4aMJXSqk4oQlfKaXihCZ8pZSKE5rwlVIqTtjCHUBPsrOzTWFhYbjDUErFo+Ji389Jk8IbRz9t2LChxhiTc7IyQSV8EZkHPApYgaeNMQ902z8ZeBY4C/h3Y8xD/u1jgKVAHuAFnjLGPNrX+xUWFrJ+/fpgQlNKqdC6+GLfz/ffD2cU/SYiB/oq02fCFxEr8ARwOVAKrBOR5caYHQHFjgB3ANd2O9wD/MgYs1FEUoENIvJOt2OVUkoNg2D68GcBJcaYfcYYN7AMWBhYwBhTZYxZB7R3215ujNnof94I7AQKQhK5Ukqpfgkm4RcAhwJelzKApC0ihcCZwKf9PVYppdTgBdOHLz1s69d8DCKSArwC3GmMaeilzCJgEcDYsWNP2N/e3k5paSkul6s/b61imNPpZPTo0djt9nCHolRUCCbhlwJjAl6PBsqCfQMRseNL9s8bY17trZwx5ingKYCZM2ee8AeltLSU1NRUCgsLEenpb5CKJ8YYamtrKS0tpaioKNzhKBUVgunSWQdMEJEiEXEA1wHLgzm5+DLz74GdxpiHBx4muFwusrKyNNkrAESErKws/canVD/02cI3xnhE5HbgbXzDMp8xxmwXkVv9+5eISB6wHkgDvCJyJzAVOB34JrBVRDb7T/kTY8yKgQSryV4F0t8HpfonqHH4/gS9otu2JQHPK/B19XT3ET1fA1BKKTXMdGqFINXV1fG73/1uwMc/8sgjtLS0HLftl7/8Jc8//zyvvfYaO3b0/9aE5cuX88ADD/RdcIDuu+8+HnroIQDuvfdeVq1aBfT8WQZqyZIlLF269KRlNm/ezIoVA/pSqNSA1LW2c9b971DZEFtdhprwgzQUCX/lypVcccUVJ034Ho+n13MuWLCAe+65Z8Ax9cf999/PZZddBoQ24d96663ceOONJy2jCV8Nt4p6F0da3LxfXBXuUEJKE36Q7rnnHvbu3cuMGTO46667AHjwwQc555xzOP300/nZz34GQHNzM1dffTVnnHEG06ZN48UXX+Sxxx6jrKyMSy65hEsuuQSAhoYG3G43e/bsYfny5dx1113MmDGDvXv3cvHFF/OTn/yEiy66iEcffZTXX3+d2bNnc+aZZ3LZZZdRWVkJwB/+8Aduv/12AG6++WbuuOMOzjvvPMaPH8/LL798wmfoKTbwTWVx9913M2vWLGbNmkVJSckJx9588828/PLLPX6WQL2d68CBA8ydO5fTTz+duXPncvDgQeD4bxEXX3xx17ETJ05k9erVuN1u7r33Xl588UVmzJjRFbNSQ8Xd4aWuxXcP6eo9NWGOJrQicvK0Pt15J2ze3He5/pgxAx55pNfdDzzwANu2bWOz/31XrlzJnj17WLt2LcYYFixYwIcffkh1dTWjRo3ijTfeAKC+vp709HQefvhh3nvvPbKzswFYtWoVc+fO5bzzzmPBggVcc801fOUrX+l6v7q6Oj744AMAjh49yieffIKI8PTTT/PrX/+a3/zmNyfEWF5ezkcffcSuXbtYsGDBcecDeOutt06IrVNaWhpr165l6dKl3Hnnnfz973/vsR7uuOOOEz5Ldz2d6/bbb+fGG2/kpptu4plnnuGOO+7gtddeO+FYj8fD2rVrWbFiBT//+c9ZtWoV999/P+vXr+fxxx/v+R9HqRCqbXIDhlNzU/iopAav12CxxMalSG3hD9DKlStZuXIlZ555JmeddRa7du1iz549TJ8+nVWrVnH33XezevVq0tPTezz+rbfeYv78+b2e/2tf+1rX89LSUq688kqmT5/Ogw8+yPbt23s85tprr8VisTB16tSubwGBThbb9ddf3/VzzZo1QdVBb3o615o1a7jhhhsA+OY3v8lHH33U47Ff/vKXATj77LPZv3//oOJQaiCqG9tw2q1cMXUkdS3tbC/r8V7RqBSdLfyTtMSHizGGxYsX893vfveEfRs2bGDFihUsXryYK664gnvvvfeEMmvXruXJJ5/s9fzJycldz7/3ve/xwx/+kAULFvD+++9z33339XhMQkLCcfF1N3HixF5jCxziONjhjsGcq7ftnZ/BarWe9PqFUkNhR1kDLW4PeelOphf4GkSrS6qZPrrnhlu00RZ+kFJTU2lsbOx6feWVV/LMM8/Q1NQEwOHDh6mqqqKsrIykpCS+8Y1v8OMf/5iNGzeecPz27duZPHkyVqu1x3N3V19fT0GBb/qi5557bsCfobfYgK6+8RdffJFzzz33pOfpK96eznXeeeexbNkyAJ5//nkuuOCCoOPu6/2UCpVXN5YiIqQ57WQkORiXlcTq3bHTjx+dLfwwyMrK4vzzz2fatGnMnz+fBx98kJ07d3YltJSUFP70pz9RUlLCXXfdhcViwW63d7XiFy1axPz588nPz+fqq69m3rx5Xee+7rrr+M53vsNjjz3W48XW++67j69+9asUFBQwZ84cPv/88wF9hq1bt/YYG0BbWxuzZ8/G6/XywgsvnPQ8gZ/lvffeO2F/T+d67LHHuOWWW3jwwQfJycnh2WefDTruSy65hAceeIAZM2awePHi47q7lAqlf+yq4lqHFau/z37aqHRW7qigxe0hyRH96VJ6+uofbjNnzjTdF0DZuXMnU6ZMCVNEoXX55ZezdOlS8vPzwx0KcGzBmd4uwobrXMGIpd8LFV51LW5m3P8O775+H9kpDnb8eTlbDtXxwFu7ePZb53DJpNxwh3hSIrLBGDPzZGW0SycM3nnnnYhJ9kopn00H6wBIcli7tk3OTyXBZuGnf93G8i1lPV4biyaa8BX79+8PWYs8lOdSajhtPHgUi4DTfizhJ9is3D1vMjarcMcLm/juHzeEMcLBi6qEH+1/XVVo6e+DCqWNB44yLiuZ7kPup+Sn8Ytrp3PxxBxW7aykwxu9v3dRk/CdTie1tbX6n1wBx+bDdzqd4Q5FxYAOr2HToTpOzU3pcb/FIhRmJ+M1cLTFPczRhU7UXHYePXo0paWlVFdXhzsUFSE6V7xSarB2VzbS4u5gQi8JHyA90beyWm2Tm+yUhF7LRbKoSfh2u11XNlJKDYmNB48CMHFkaq9l0vwJv6apjUn0Xi6SRU2XjlJKDZWNB+pIT7STm9p7yz09IOFHK034Sqm4VN/azsclNRxpdrPx4FEm5KacdFqRdGdnwtc+fKWUiipPvr+XJR/s7Xo9pyjzpOWTE6zYLBLVLXxN+EqpuHToSAuZyQ7mnZZHeb2L8089+f0jIkJ6op1aTfhKKRVdyutbyUtz8sUzRgV9TFqiPaq7dLQPXykVlyrqXWQlO/p1TJrTRnVj9LbwNeErpeKO12uoamxjRH8TfpR36WjCV0rFnZrmNjxe0+8Wfrq/Syda7/jXhK+UijuV9b5Wen9b+OmJdtwdXpraonM1Nk34Sqm4U17fCkDmABI+RO9YfE34Sqm4U9ngAgaT8KOzH18TvlIq7pTXu7DIsbtng3VsArUYTvgiMk9EikWkRETu6WH/ZBFZIyJtIvLj/hyrlFLDraLBRWayA0v3ye/70DmBWnWsdumIiBV4ApgPTAWuF5Gp3YodAe4AHhrAsUopNawqG1yMSOpfdw5AWud8OlE6Fj+YFv4soMQYs88Y4waWAQsDCxhjqowx64D2/h6rlFLDrbzO1e/+ewCrRUh12qhtjt2EXwAcCnhd6t8WjKCPFZFFIrJeRNbrIidKqaFU0eDq95DMTumJdmoaY7RLB+ipkyvYuw6CPtYY85QxZqYxZmZOTk6Qp1dKqf5pdLXT4u4gcwBdOuDr1qmJ4RZ+KTAm4PVooCzI8w/mWKWUCrmK+oENyezka+HHbsJfB0wQkSIRcQDXAcuDPP9gjlVKqZCrGOAY/E7pUTxjZp/TIxtjPCJyO/A2YAWeMcZsF5Fb/fuXiEgesB5IA7wicicw1RjT0NOxQ/VhlFKqL+UhaOE3tXlwtXfgtFtDGdqQC2o+fGPMCmBFt21LAp5X4OuuCepYpZQKl0p/wh/IsEw4Nha/ttlNQUZiyOIaDnqnrVIqrlQ0uEh12nDYBpb+uqZXiMJ+fE34Sqm4MpCFTwKlJ/o6RqJxPh1N+EqpuFLR4CJjgN05AMkJvoTf4Op+n2nk04SvlIor5YNs4SfYfBdqW9wdoQpp2GjCV0rFjTZPB0ea3QO+yxbAafelzVZN+EopFbmqGnz97gO9yxboutirCV8ppSLYYG+6ArBZLNgsQku7JnyllIpYg51WoVOC3aItfKWUimQDXdqwO6fNSos7+hYy14SvlIob5fUuEmwWkhyDmxIhwWbRUTpKKRXJOpc2FOnf0obdJdit2qWjlFKRrKJ+YCtddefQFr5SSkW2ivrWAU+aFijBaqFVR+kopVRk8noNlQ1tIWnhJ9gtetFWKaUiVW2zG4/XhCbh26zapaOUUpGqa0hmKLp0bDoOXymlIlbXSlcpoejSseqdtkopFak6p1UIxUVbp82Cy92BMWbQ5xpOmvCVUnGhst6FRSDDv2LVYCTYLBjA1e4dfGDDSBO+UioulNe7GJHkwGIZ3E1XAI6uOfGja6SOJnylVFyobAjNTVfgG5YJRN1YfE34Sqm4UFbfOqiFTwI5o3ROfE34Sqm4UNngCsmQTIjeZQ414SulYl6jq53mto6Qd+lowldKqQgTqnnwO3W28Fvb9aKtUkpFlIp6/1q2IUv4MdzCF5F5IlIsIiUick8P+0VEHvPv/0xEzgrY9wMR2S4i20TkBRFxhvIDKKVUXzYcOIoA+emhST8xm/BFxAo8AcwHpgLXi8jUbsXmAxP8j0XAk/5jC4A7gJnGmGmAFbguZNErpVQfjDG8srGU0wrSyAjVRVu7v0sn1hI+MAsoMcbsM8a4gWXAwm5lFgJLjc8nQIaI5Pv32YBEEbEBSUBZiGJXSqk+bTx4lINHWvjCqTkhO2dnCz8Wx+EXAIcCXpf6t/VZxhhzGHgIOAiUA/XGmJUDD1cppfrn5Q2HSbBZmFWUGbJzOmK1Swfo6T7k7jMG9VhGREbga/0XAaOAZBH5Ro9vIrJIRNaLyPrq6uogwlJKqZNztXfw98/KmFWYidM+uIXLA1lE/FMkx94onVJgTMDr0ZzYLdNbmcuAz40x1caYduBV4Lye3sQY85QxZqYxZmZOTui+eiml4te7O6todHn4wsTQ5xSnPfoWQQkm4a8DJohIkYg48F10Xd6tzHLgRv9onTn4um7K8XXlzBGRJPEtEz8X2BnC+JVSqlevbykjM9nBaflpIT93NC6CYuurgDHGIyK3A2/jG2XzjDFmu4jc6t+/BFgBXAWUAC3At/z7PhWRl4GNgAfYBDw1FB9EKaW621fTxPjs5JDMkNmdw2aJuhZ+nwkfwBizAl9SD9y2JOC5AW7r5difAT8bRIxKKTUgFfUuCrOSh+TcCTZL1K16pXfaKqViUnObhwaXh6wQ3V3bnW8h89i7aKuUUlGnc0nDzJSEITl/NPbha8JXSsWkivrQTpjWXYI9+vrwNeErpWJSuT/hD2WXjrbwlVIqAlTUtwIwIkTz53Tnu2irffhKKRV25fUu0py2rmkQQk378JVSKkJU1Idu0fKeJNittHcYPB3eIXuPUNOEr5SKSWV1rUOb8DsnUIuisfia8JVSMam8YYhb+LbomxNfE75SKua42juoa2knK3loxuADOP0LmWvCV0qpMBrqMfhwrIUfTWPxNeErpWJO+bAk/M5Vr6JnaKYmfKVUzKlo8I3BH6qbrsB3py1oC18ppcKqs4U/Qrt0jqMJXykVcyrqXaQk2EK6rGF3XV06mvCVUip8yof4pisIGIevCV8ppcKnvH5ob7oC3522QFTNia8JXykVc4Z6WgUAp7+F79I7bZVSKjzaPB3UNLmHdIQOgM1qwWoR7dJRSqlwGY6brjo5o2whc034SqmYsruyCYCCjMQhfy9HlE2RrAlfKRVTiisaABg9ImnI3yvBbtXZMpVSKlx2VTSSm5pAomPoxuB38i2CoqN0lFIqLIorGoeldQ/gtFlpbtMWvlJKDTu3x8vnNc2MzRz6/nuARIeVpjZt4Sul1LDbW92Ex2uGrYWfaNeEr5RSYVFc0QjA2MxhSvgOK42u9mF5r1AIKuGLyDwRKRaREhG5p4f9IiKP+fd/JiJnBezLEJGXRWSXiOwUkXND+QGUUqpTcWUjNouQn+4clvdLirUuHRGxAk8A84GpwPUiMrVbsfnABP9jEfBkwL5HgbeMMZOBM4CdIYhbKaVOUFzRSH6GE5t1eDovEu1WXO1e2ju8w/J+gxVMrcwCSowx+4wxbmAZsLBbmYXAUuPzCZAhIvkikgZcCPwewBjjNsbUhTB+pZTqsqu8gTHD1H8PvhY+QJMrOlr5wST8AuBQwOtS/7ZgyowHqoFnRWSTiDwtIsk9vYmILBKR9SKyvrq6OugPoJRSAI2udsrqXYwZpv57oGusf7R06wST8KWHbSbIMjbgLOBJY8yZQDNwwjUAAGPMU8aYmcaYmTk5OUGEpZSKJV5v97QSnA93V/NxSU3XBdvhbOEn2m0ANETJhVtbEGVKgTEBr0cDZUGWMUCpMeZT//aX6SXhK6Xi16f7arnlD+v4j2umct2ssUEf52rv4NtL1+P2eElz+tLZcI3Bh9js0lkHTBCRIhFxANcBy7uVWQ7c6B+tMweoN8aUG2MqgEMiMslfbi6wI1TBK6ViwwtrD9Ls7uCeV7fy23f3YExwrf0NB47i9ni58rQ8slMSKBiRSHZKwhBHe0y0den02cI3xnhE5HbgbcAKPGOM2S4it/r3LwFWAFcBJUAL8K2AU3wPeN7/x2Jft31KqRhUXNHIvz2/gWdvnsXYrJN3sbS4Pby9o5KLJubQ4TX85p3dWCzCbZec2uf7rNlbi0XgazPHDMvcOd0l+le9aoySFn4wXToYY1bgS+qB25YEPDfAbb0cuxmYOYgYlVJR5qX1h9hb3czznx5g8VVTTlp21c4qWt0dXDgxh8l5qbg7vDz27h6uPbOga4pjYwwiJ14q/HhvDeNzUsKS7OFYl05jlLTw9U5bpVRIGWN4c1sFAC9vKMXtOfkY9b9tPkxmsoPJealYRPjmnHEYA796cxfga8XP+eW7/GNX5XHHNbd5+Ky0nqn5aUPzQYLQ+YcmWu621YSvlAqprYfrOVzXyuyiTGqb3Sck6kBHm918UFzNueOzsPhb8NkpCVx9ej7Lt5Txu/dL+Naza6lsaOO/P9h33LHr9h/B4zWcNip8Cd/hX+Ywli7aKqVU0N7cVoFF4FvnF5GZ7GDZ2kO9ln39szI8XsP5p2Yft33BGaMYkWTn128VMzLdydXT8/n08yPsrW7qKrNmXy02izBxZOqQfZa+iAhJUTSBWlB9+EopFQxjDCu2lnPaqHTSE+1cNDGH1zYdpqyulVH+/vgWt4ffr/6cN7aWs6uikTGZiRR2u7DrtFv59hfG8+Huav71giI6vIa3tlfw4rpD/MR/TWDN3lpOzU3BaQ9P/30n3wRq0ZHwtYWvlAqZXRWNHKhtYVZRJgAXT8zBAPe8upUPdlfzfnEVVzz8Ib95ZzcAX589lp/Mn9LjBdmzxo7gzssmkuq0k5Hk4OyxI3hp/SHaPB00uNrZdji8/fedoinhawtfKRUynd05M8eNACA3zclXzh7Niq3lfLjbN2XKqHQnP7tmKpP7mawvnZzL2v1H+K939vBZaR1eQ1j77zv55sSPjou2mvCVUiHz5tZyJuWlkpHk6Nr2L2eN5ounj2JLaR11Le1cNDEHh63/nQvTR6eTk5rAkg/2kpFk5+uzxzIlAlr4SdrCV0rFm5KqJvZUNXHTuYUn7HPYLJxTmDmo81tEuP2SU6lscDFnfBb2YZoCuS+Jdis1Te5whxEUTfhKqZB4a1s5QFf//VCYODI1rKNyehJNq15Fxp9IpVTUe3NbBRNHppCZ7Oi7cAxJctiiZlimJnyl1KAdrG1he1kDswqzwh3KsEu0W2nvMLR5OsIdSp804SulBu3Nru6cEWGOZPgdm14h8lv5mvCVUgNmjKG6sY3XPytjfHYyOanDs3h4JImmOfH1oq1SakDe2lbBD17cTGu7ryvj+n4sXBJLOqdIjoZ+fE34SqkBWbm9AqtFuOncQnJTE5g+Oj3cIYVFZws/GpY51ISvlBqQzYfqmJSXyrxpeeEOJawSHb40Gg1dOtqHr5Tqt/rWdvbVNHNKTkq4Qwm7aFr1ShO+Uqrfth2uB+CUnOQwRxJ+SVG0rq0mfKVUv20+VAfA+Gxt4UfTQuaa8JVS/fZZaR156U5SnHoZ0G61YLdKVFy01YSvlOq3zYfqOCVbu3M6JTlsetFWKRV7KhtcVDa0cUqudud0SoySZQ414Sul+mWLv/9eR+gcEy2rXmnCV0r1y5bSOiwChVnapdMp0R4dUyRrwldK9cuWQ/WMzUwa0KpVsUpb+EqpmNPc5mHDgaNMiLBFSMItya4JXykVY97ZUUlrewfnjo+/ee9PJtERQxdtRWSeiBSLSImI3NPDfhGRx/z7PxORs7rtt4rIJhH5e6gCV0oNv9c2HSY7xcGkPG3hB0pyWGlyeTDGhDuUk+oz4YuIFXgCmA9MBa4Xkandis0HJvgfi4Anu+3/PrBz0NEqpcKmpqmN1XtqOO+UbCwi4Q4noiTarXQYg6vdG+5QTiqYFv4soMQYs88Y4waWAQu7lVkILDU+nwAZIpIPICKjgauBp0MYt1JqmL3xWTkdxnD+qdnhDiXidK161RbZI3WCSfgFwKGA16X+bcGWeQT4P8BJ//SJyCIRWS8i66urq4MISyk11FZur+Dnr29n2+F6Xtt0mLGZSYzNTAp3WBEnJcE3xURdS/Qn/J6+u3XvqOqxjIhcA1QZYzb09SbGmKeMMTONMTNzcnKCCEspNdQefXcPz/5zP9f89iM2Harj/FP0Ym1P0hLtgK/bK5IFM/NRKTAm4PVooCzIMl8BFojIVYATSBORPxljvjHwkJVSw6G+tZ0dZQ3Mn5ZHbmoCO8obuGhSbrjDikhpTl/Cr21yhzmSkwumhb8OmCAiRSLiAK4Dlncrsxy40T9aZw5Qb4wpN8YsNsaMNsYU+o/7hyZ7paLDus+PYICZhZnMm5bPDy+fRLq/JauOl54UIy18Y4xHRG4H3gaswDPGmO0icqt//xJgBXAVUAK0AN8aupCVUsPhk3212K3CqTpnTp9SEmxYJAYSPoAxZgW+pB64bUnAcwPc1sc53gfe73eESqmwWLOvlgm5qTqFQhAsIqQn2mOiS0cpFWc6+++n5KeFO5SokZZoj/gWviZ8pdQJOvvvp47ShB+sNKedGm3hK6Wijfbf9196op3qRm3hK6WijPbf919aop0jzdrCV0pFkZqmNu2/H4D0RDut7R00R/CsmZrwlVLHeXlDKQY4V++q7Zf0KLjbVhO+UqqLMYYX1h5kcl4qBRmJ4Q4nqqQn+ka5R/KFW034Sqkua/bVcqC2hUsn6xQK/ZWe6AC0ha+UihLL1h4iOcHK7CLtzumvNKevhR/JN18FdaetUip2fbqvlvJ6F6MyEnlzWzmXTMrV0TkDEA19+JrwlYpjlQ0ubnp27XErNWl3zsDYrBaSE6zUasJXSkWiR1btwdNh+PerptDs9iAI47KSwx1W1EpPjOy7bTXhKxWnSqqa+Mu6Q1w+dSTTCtLDHU5MSE+0Ux3BLXztqFMqTj349i4cNgtfOrP7iqVqoHzz6WjCV0pFiKoGF/f+bRtvb6/kmtPzu5bnU4OXHuEzZmqXjlIxzhjDXzcdZtPBOsrrW/loTw3tXsPcyblcc/qocIcXU9IS7TS0enB7vBE50kkTvlIx7oPd1fzwL1tITrCSnZLAuadksXBGASPTnOEOLeZ0Ds080uwmLz3y6lcTvlIxrMNr+MWKneSlJfDgV87AZo28VmcsSXceG4sfiQlf//WVimGvbChld2UTXztnrCb7YRDpi5nrb4BSMarF7eGhlcVMyE1hdlFmuMOJC8futo3Msfia8JWKQYeOtHDLH9ZR1djGDbPHIiLhDikupPm7dCL1blvtw1cqhvimNz7E/31jB8bAdy8cz+Q8XchkuDjtFhJsFqoidKlDTfhKxYiapjbufuUz3t1ZxbSCNBZ94RRyUhPCHVZcERGykh1U1LvCHUqPNOErFQPe21XFj1/aQoOrnRvPHceVp+Vh0W6csMhMdlBW1xruMHqkCV+pKNPq7uD7yzaR4rRx0cQc1u8/yh8/OcDYzCT+z7zJjM1MCneIcS0rJYFdFQ3hDqNHmvCVijL/tWo3K3dUkpJg49WNhwG4aloeXztnbETe3RlvMpMdVDe24enwRtxQ2KASvojMAx4FrMDTxpgHuu0X//6rgBbgZmPMRhEZAywF8gAv8JQx5tEQxq9UXNlyqI6nV+9j7uRcbjm/iH01TdisFgp1SuOIkZXswGugqrGNURG2LnCff35ExAo8AcwHpgLXi8jUbsXmAxP8j0XAk/7tHuBHxpgpwBzgth6OVUoFoc3TwY9f2kJGkoMbZo/FYhFOzU3VZB9hslJ8a9uW10deP34w3zdmASXGmH3GGDewDFjYrcxCYKnx+QTIEJF8Y0y5MWYjgDGmEdgJ6FysSg3A06s/Z09VE/96QRFJDu2NjVRZyb6RUWV1kTdSJ5iEXwAcCnhdyolJu88yIlIInAl82tObiMgiEVkvIuurq6uDCEup+FHV4OLx90o4p3AEZ40dEe5w1El0tvAjcWhmMAm/p7Fdpj9lRCQFeAW40xjT4+VrY8xTxpiZxpiZOTk5QYSlVHSrbDuPAVEAAA2CSURBVHDx3Mf78XR4+yz70Mpi2j1ebpg1bhgiU4ORaLeSaLdQFoFdOsF8LywFxgS8Hg2UBVtGROz4kv3zxphXBx6qUrHlnlc+473iamqb3fzw8om9ltt2uJ6X1pdy1fT8iJyBUR1PRMhKSaA8Srt01gETRKRIRBzAdcDybmWWAzeKzxyg3hhT7h+983tgpzHm4ZBGrlQUe29XFe8VV5OTksBv393Dx3trTihztNnNs//8nP/9/AZSnTZdijCKZCY5IrKF32fCN8Z4gNuBt/FddP2LMWa7iNwqIrf6i60A9gElwP8A/+bffj7wTeBSEdnsf1wV6g+hVDRp7/Dyn3/fQX66k198aTr5GU7uXLb5uCl1395ewZxfvsvPX9+Bw2rhe5dOIDlBL9RGi6wUB+UR2Icf1G+QMWYFvqQeuG1JwHMD3NbDcR/Rc/++UnHruY/3s6+mmbuunESK08b3Lp3AvX/bxhd/+xEPffUM6lra+f6yTRRmJ/PtC4oYp8Muo05mcgI1jW0Rt9ShNhmUGkY7yxt46O1iZozJ4MwxGQAUZiVz7zWn8eQHJXz96U+xCEwcmcpdV07S4ZdRKivZgcF3YX5MBE11ob9NSg2T+tZ2bv3TBhIdVr574fjj5qg/NTeFX3xpOi+tL+VIs5tFF47HabeGMVo1GMduvtKEr1TcqGxw8X5xFTaLhde3lFF6tJWfXj2FjCTHCWUTbFa+MUeHXcaCzpuvIu1uW034Sg2R+pZ2vrpkDQePtHRtu+nccbogSRzITD7Wwo8kmvCVGgIdXsP3XthIWV0ri+dPZmSaE5vFNz5bxb5Eh5Vkh5XyCJsXXxO+UiFmjOHXb+/iwz01fPsLRZw+OiPcIakwyExxUKYtfKViV6OrnZ/8dRuvbylj7uRc5k4eGe6QVJhkJSdoH75SsehIs5tVOyt54r0SDh1p4Wszx7Bgxqhwh6XCKCvZwYaDRzHGHDciK5w04Ss1CF6vYfFft/Ly+lI6jCEvzcl/XD2Vyfl6YTbejclM4t1dVVQ2tEXMHEia8JUahF+9tYsX1x3isikjuXRyLoVZSRHTmlPhVZTtu0N66+H6iEn4kXPPr1JR5s+fHuS/P9zH5VNHcsv5hRRlJ2uyV13GZSVhEV/CjxTawleqn7xew/+s3sev3/JNkXDTuYWa6NUJEmxWCjIS2a4JX6noVF7fyl0vfcZHJTXMKsrk1gtPwWrRZK96VpidzGea8JWKLjVNbTz5/l7+uOYACHz7C0VcOilXW/bqpMZnJ7N6Tw1VDS5y08Lfj68JX6mT8HR4eW7NAR5+p5hWdwdfmJDDl88siIj/vCryFQZcuJ0bAb8zmvCV6qa2qY0NB45SXNHIG1vL2VXRyBlj0rlxTiGjMhLDHZ6KIoVZyQiw7XADc6eE/yY8TfhK+e2tbuLp1ft4ZcNh3P6FxQsyEvnBZRM5p3CEdt+ofnParRSMSIyYkTqa8FVcKqtrpbrRt6RgcWUjr2wo5dPPj2C3ChdOyOHCiTmMGZFEokPnpFeDMy4rma2H68IdBqAJX8WZ3ZWN/PYfJfx9SxkmYHt+upP/NXMMl0zK6XGueqUGanx2Mv8sqaG6sY2c1PDOlqoJX8WkNXtreWhlMQk2C6NHJNLs7mBraT0Hj7SQaLfwxTNGMSkvFYD0RDvj9aYpNUQ677jdcOAo86blhTUWTfgqprjaO/jNymKeXv05OakJZCTZ2VnegN1qoTA7mS9MyOaiiTmkOu3hDlXFiQm5KYxIsvPnTw9owlcqVP6xq5Kfv76DA7UtXDYll6/PHqfrwqqws1ktXDZlJC9tKKWkqpFTc1PDF0vY3lmpIOwsb+C94iq8XoMxkJZoZ0SyA5e7g89rmzl8tJWmNg/VjS62Hm5gVIaTxfMn66IjKqJcNmUkr20+zLP/3M//+9L0sMWhCV9FpKpGF795ezd/WX/ouIurgawWITvFQZLDhtNu4euzxzLvtDxsVp0TUEWWtEQ755+SzasbD3PXlZPCNjBAE76KKEea3fz3h3tZ+vEB2ju8zJ+Wx8IZBST5h0c2uztodLVjt1rITknQeWxU1Jg3LY/3d1fz57UH+beLTw1LDJrwVVg1tXnYU9nIxoN1rNlbyz9LanC1d3DeKVn8y9mjyU8//s7W9EQL6Yl6wVVFn3FZyZwxJp3H3t3DhRNymFaQPuwxaMJXQ8rrNRw40sK2w/WUVDVxoLaZw3WtNLR6ONripsp/8xNAXloC552SxbxpeYwekRTGqJUaGrdeeAo/fW0b31m6nuW3XzDs4/KDSvgiMg94FLACTxtjHui2X/z7rwJagJuNMRuDOVZFlgZXO4ePtnL4aCvlDS68XoPVItitgtViwSLQ2t5BS1sHIr5bx+1Wob3D4PZ4qW1uo7KhjcoGFxX1LsrqW2lu6wBAgOzUBLKSHaQ6beSlO7l4kpMxIxIpyk4mKyW8N6UoNdQykhz86IpJ3Pf6dr6zdD2/vf5MxmQOX+Omz4QvIlbgCeByoBRYJyLLjTE7AorNByb4H7OBJ4HZQR4bVYwx/p8B27rvAzq8hg6vweM1eDt/muNfd5YBSLBZSHRYcdqtOO0WHFZLv24E8noN7g4vrvYO6lvbqW9tp66lvet556O5zUOru8OXtN0dtLo7aHF7aHF3UN3URqPLM6j6sQiMSHKQmewgI8lOUXYy47KSKcpOpiAjEYdNL6iq+FaUncxtF5/K4+/t4ZKH3ucbc8Yxf1oe47KSyU1NwDKE16WCaeHPAkqMMfsARGQZsBAITNoLgaXGl/E+EZEMEckHCoM4NmTO/s93aHF3YDg+KXfl5q7XwSXt7mWincNmIdH/ByXBFvjTSnqSgyn5aeSmJpCTmkBuqpOcVN9F0c4/TB3G98cqwWbBabdiALfHi6fDi81qwWYRUpw2LHrHqopinQMBUhKGrsf70sm5nD46nWVrD/LHNQf4w8f7AchOcbD+p5cP2fsG84kKgEMBr0vxteL7KlMQ5LEAiMgiYJH/ZZOIFAcRWzTIBmrCHUQE0fo4ntbH8SKnPsYM/70cBwD5j+M29ac+xvVVIJiE31NzrXu7t7cywRzr22jMU8BTQcQTVURkvTFmZrjjiBRaH8fT+jie1sfxQl0fwST8UmBMwOvRQFmQZRxBHKuUUmoYBHMFbR0wQUSKRMQBXAcs71ZmOXCj+MwB6o0x5UEeq5RSahj02cI3xnhE5HbgbXxDK58xxmwXkVv9+5cAK/ANySzBNyzzWyc7dkg+SeSKuW6qQdL6OJ7Wx/G0Po4X0voQE0vDUJRSSvVKB0UrpVSc0ISvlFJxQhP+AIjIMyJSJSLbAradISJrRGSriLwuImn+7XYRec6/faeILA445mz/9hIReUyidI29ftaHQ0Se9W/fIiIXBxwT9fUhImNE5D3/v/V2Efm+f3umiLwjInv8P0cEHLPY/5mLReTKgO1xVx8ikuUv3yQij3c7VzzWx+UissH/uTeIyKUB5+p/fRhj9NHPB3AhcBawLWDbOuAi//NbgP/0P78BWOZ/ngTsBwr9r9cC5+K7X+FNYH64P9sw1MdtwLP+57nABsASK/UB5ANn+Z+nAruBqcCvgXv82+8BfuV/PhXYAiQARcBewBrH9ZEMXADcCjze7VzxWB9nAqP8z6cBhwdTH9rCHwBjzIfAkW6bJwEf+p+/A/xLZ3EgWURsQCLgBhr8U0+kGWPWGN+/3lLg2iEPfgj0sz6mAu/6j6sC6oCZsVIfxphy45840BjTCOzEd8f5QuA5f7HnOPbZFuJrELQZYz7HN9JtVrzWhzGm2RjzEeAKPE8c18cmY0znvUvbAaeIJAy0PjThh842YIH/+Vc5dsPZy0AzUA4cBB4yxhzB949cGnB853QUsaK3+tgCLBQRm4gUAWf798VcfYhIIb4W2qfASOO7NwX/z1x/sZNNSxKP9dEbrQ9fo2mTMaaNAdaHJvzQuQW4TUQ24Puq5vZvnwV0AKPwfWX/kYiMpx/TTkSp3urjGXy/nOuBR4CPAQ8xVh8ikgK8AtxpjGk4WdEetvVrWpJo0I/66PUUPWyLm/oQkdOAXwHf7dzUQ7E+60MXQAkRY8wu4AoAEZkIXO3fdQPwljGmHagSkX8CM4HV+Kaa6BRT0070Vh/GGA/wg85yIvIxsAc4SozUh4jY8f1nft4Y86p/c6WI5Btjyv1fx6v823ublqSU+KyP3sRtfYjIaOCvwI3GmL3+zQOqD23hh4iI5Pp/WoCfAkv8uw4Cl4pPMjAH2OX/2tYoInP8V9dvBP4WhtCHRG/1ISJJ/npARC4HPMaYHbFSH/7Yfw/sNMY8HLBrOXCT//lNHPtsy4Hr/P2yRfjWlFgbx/XRo3itDxHJAN4AFhtj/tlZeMD1Ee6r1tH4AF7A1yffju8v7b8C38d3xX038ADH7mJOAV7Cd8FlB3BXwHlm4uvr3gs83nlMtD36WR+FQDG+i1WrgHGxVB/4RpgY4DNgs/9xFZCF72L1Hv/PzIBj/t3/mYsJGGkRx/WxH98ggCb/79PUeK0PfI2l5oCym4HcgdaHTq2glFJxQrt0lFIqTmjCV0qpOKEJXyml4oQmfKWUihOa8JVSKk5owldKqTihCV8ppeLE/wcxw/Zw0o5KXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#removing 'year=1' which were originally NaNs in ChEMBL:\n",
    "_ = kdeplot(interaction_dates.data[interaction_dates.data>1950], shade=True)\n",
    "#bonus - set 'cumulative=True' in kdeplot to visualize the amount of data that will be in the test set.\n",
    "plt.axvline(2015, c='red', label='test/train split point')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can thus be used to perform time-split cross validation, which simulates prospective validation. The below sets a year, and creates a training matrix with all interactions equal to or before that year, and a test matrix with all interactions from after that year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test = utils.load_time_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse.csr_matrix(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction_matrix = utils.load_subset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test = utils.train_test_split(interaction_matrix, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train, test = utils.load_time_split()\n",
    "name = 'hpo_implicit_bpr'\n",
    "params = utils.read_params(name)\n",
    "preds = utils.train_implicit_bpr(params, train)\n",
    "ranks = utils.evaluate_predictions(preds, test, train)\n",
    "mean, median, kde, ecdf = score_ranks(ranks)\n",
    "print(mean, median)\n",
    "for _ in range(16):\n",
    "    preds+=utils.train_implicit_bpr(params, train)\n",
    "    ranks = utils.evaluate_predictions(preds, test, train)\n",
    "    mean, median, kde, ecdf = score_ranks(ranks)\n",
    "    print(mean, median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ecc8982d3747859459c1f256723568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 5.28 s, sys: 320 ms, total: 5.6 s\n",
      "Wall time: 5.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, test = utils.load_time_split()\n",
    "name = 'hpo_implicit_bpr'\n",
    "params = utils.read_params(name)\n",
    "preds_imp = utils.train_implicit_bpr(params, train)\n",
    "#ranks = utils.evaluate_predictions(preds, test, train)\n",
    "#mean, median, kde, ecdf = score_ranks(ranks)\n",
    "#print(mean, median)\n",
    "for _ in tqdm_notebook(range(1)):\n",
    "    preds_imp+=utils.train_implicit_bpr(params, train)\n",
    "    #ranks = utils.evaluate_predictions(preds, test, train)\n",
    "    #mean, median, kde, ecdf = score_ranks(ranks)\n",
    "    #print(mean, median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_imp = utils.evaluate_predictions(preds_imp, test, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median corresponds to the minimum of the l1 norm! \n",
    "#https://statmodeling.stat.columbia.edu/2006/11/16/bayesian-inference-median/\n",
    "l1norm=list()\n",
    "for i in np.linspace(1,25,500):\n",
    "    diffs = np.abs(i-ranks_imp)\n",
    "    l1norm.append(np.sum(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(l1norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(1,25,500)[187]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(ranks_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1,25,500),l1norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laplace distribution is related to l1 norm. \n",
    "#so we could use laplace as the likelihood for pymc3:\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "with pm.Model() as model:\n",
    "    #prior:\n",
    "    m = pm.Normal('m', mu=5, sigma=6.0)\n",
    "    bee = pm.HalfNormal('bee', sigma=6.0)\n",
    "    #likelihood:\n",
    "    y = pm.Laplace('y', mu=m, b=bee,observed=ranks_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [bee, m]\n",
      "Sampling 2 chains, 0 divergences: 100%|██████████| 2000/2000 [00:01<00:00, 1168.69draws/s]\n"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "    trace = pm.sample(draws=500, tune=500, chains=2,\n",
    "                      target_accept=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdeplot(trace['m'])\n",
    "plt.vlines(pm.stats.hpd(trace['m']),0,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.plot_posterior(trace, var_names=['m'])\n",
    "plt.savefig('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdeplot(trace['bee'])\n",
    "plt.vlines(pm.stats.hpd(trace['bee']),0,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "plt.plot(np.linspace(-20,40,100), [stats.laplace(10.5,31).pdf(i) for i in np.linspace(-20,40,100)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.stats.hpd(trace['m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace, var_names=['m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace['m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikits.bootstrap as boot\n",
    "#import numpy as np\n",
    "boot.ci(ranks, np.median, n_samples=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "medians = list()\n",
    "for _ in range(1000):\n",
    "    beep = np.random.choice(ranks, 500)\n",
    "    medians.append(np.median(beep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(medians)[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(medians)[975]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(medians,bins=250)\n",
    "#kdeplot(medians)\n",
    "plt.axvline(8, c='k')\n",
    "plt.axvline(13, c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train, test = utils.load_time_split()\n",
    "name = 'hpo_lightfm_warp'\n",
    "params = utils.read_params(name)\n",
    "preds_lfm = utils.train_lightfm_warp(params, train)\n",
    "#ranks = utils.evaluate_predictions(preds, test, train)\n",
    "#mean, median, kde, ecdf = score_ranks(ranks)\n",
    "#print(mean, median)\n",
    "for _ in tqdm_notebook(range(8)):\n",
    "    preds_lfm+=utils.train_lightfm_warp(params, train)\n",
    "    #ranks = utils.evaluate_predictions(preds, test, train)\n",
    "    #mean, median, kde, ecdf = score_ranks(ranks)\n",
    "    #print(mean, median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_lfm = utils.evaluate_predictions(preds_lfm, test, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack([ranks_lfm, ranks_imp]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_lfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bah = pd.DataFrame(data=np.vstack([ranks_lfm, ranks_imp]).T, columns=['lfm','bpr'])\n",
    "bah.to_csv('lfm_vs_bpr.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train, test = utils.load_time_split()\n",
    "name = 'hpo_lightfm_bpr'\n",
    "params = utils.read_params(name)\n",
    "preds_lfm_bpr = utils.train_lightfm_bpr(params, train)\n",
    "for _ in tqdm_notebook(range(8)):\n",
    "    preds_lfm_bpr+=utils.train_lightfm_warp(params, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train, test = utils.load_time_split()\n",
    "name = 'hpo_implicit_als'\n",
    "params = utils.read_params(name)\n",
    "preds_imp_als = utils.train_implicit_als(params, train)\n",
    "for _ in tqdm_notebook(range(8)):\n",
    "    preds_imp_als+=utils.train_implicit_als(params, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_lfm = utils.evaluate_predictions(preds_lfm, test, train)\n",
    "ranks_imp = utils.evaluate_predictions(preds_imp, test, train)\n",
    "mean_lfm,median_lfm,kde_lfm,ecdf_lfm = score_ranks(ranks_lfm)\n",
    "mean_imp,median_imp,kde_imp,ecdf_imp = score_ranks(ranks_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_lfm_bpr = utils.evaluate_predictions(preds_lfm_bpr, test, train)\n",
    "ranks_imp_als = utils.evaluate_predictions(preds_imp_als, test, train)\n",
    "\n",
    "mean_lfm_bpr,median_lfm_bpr,kde_lfm_bpr,ecdf_lfm_bpr = score_ranks(ranks_lfm_bpr)\n",
    "mean_imp_als,median_imp_als,kde_imp_als,ecdf_imp_als = score_ranks(ranks_imp_als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_geo = (ranks_lfm*ranks_imp*ranks_lfm_bpr)**(1/3)\n",
    "ranks_geo = (ranks_lfm*ranks_imp)**(1/2)\n",
    "ranks_geo = (ranks_lfm*ranks_lfm_bpr)**(1/2)\n",
    "mean_geo,median_geo,kde_geo,ecdf_geo = score_ranks(ranks_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_geo, median_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_imp_als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_geo, median_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kde_lfm, label='lfm_warp')\n",
    "plt.plot(kde_lfm_bpr, label='lfm_bpr')\n",
    "plt.plot(kde_imp, label='imp_bpr')\n",
    "plt.plot(kde_imp_als, label='imp_als')\n",
    "plt.plot(kde_geo, label='geo')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(ecdf_lfm, label='lfm_warp')\n",
    "plt.plot(ecdf_lfm_bpr, label='lfm_bpr')\n",
    "plt.plot(ecdf_imp, label='imp_bpr')\n",
    "plt.plot(ecdf_imp_als, label='imp_als')\n",
    "plt.plot(ecdf_geo, label='geo')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(ecdf_lfm, label='lfm')\n",
    "plt.plot(ecdf_imp, label='imp')\n",
    "plt.plot(ecdf_geo, label='geo')\n",
    "plt.legend()\n",
    "plt.xlim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_lfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean, median)\n",
    "plt.plot(kde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_ranks(ranks):\n",
    "    \n",
    "    #normal statistics:\n",
    "    mean = np.mean(ranks)\n",
    "    median = np.median(ranks)\n",
    "\n",
    "    #kde:\n",
    "    density = gaussian_kde(ranks)\n",
    "    xs = np.linspace(0,243,243)\n",
    "    density.covariance_factor= lambda : 0.25\n",
    "    density._compute_covariance()\n",
    "\n",
    "    #empirical cumulative distribution function:\n",
    "    ecdf = [(ranks<i).sum()/len(ranks) for i in range(0, 243)]\n",
    "\n",
    "    return mean, median, density(xs), ecdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2010\n",
    "\n",
    "#turn interaction dates into a masker\n",
    "dates_mask = (interaction_dates.data<=year).astype(int)\n",
    "\n",
    "#make copies that will become train / test matrices\n",
    "train = copy.copy(interaction_matrix)\n",
    "test = copy.copy(interaction_matrix)\n",
    "\n",
    "#remove 2015 and later records from train matrix\n",
    "train.data = train.data * dates_mask\n",
    "#remove all training data from the test matrix. \n",
    "test.data = test.data - train.data\n",
    "\n",
    "#remove any rows from the train matrix that have zero interactions.\n",
    "#this is the case any time a new ligand is discovered in 2015 or after. \n",
    "#we can't use link prediction on new ligands! It's a cold start problem. \n",
    "#so we remove all these ligands from the present analysis. \n",
    "row_mask = np.array((train.sum(axis=1)!=0)).reshape(1,-1)[0] #there must be a cleaner way to do that.\n",
    "train = train[row_mask] \n",
    "test = test[row_mask]\n",
    "\n",
    "train.eliminate_zeros()\n",
    "test.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'hpo_implicit_bpr'\n",
    "parameter_flag=False\n",
    "params = dict()\n",
    "for line in open('../hyperparameter_optimization/'+name+'.dat', 'r').readlines():\n",
    "    if 'Result' in line:\n",
    "        parameter_flag=False\n",
    "    if parameter_flag:\n",
    "        words = line.split()\n",
    "        params[words[0]]=float(words[1])\n",
    "        print(line.split())\n",
    "    if 'Best parameters' in line:\n",
    "        parameter_flag=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.train_implicit_bpr(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_ranks(ranks):\n",
    "    \n",
    "    #normal statistics:\n",
    "    mean = np.mean(ranks)\n",
    "    median = np.median(ranks)\n",
    "\n",
    "    #kde:\n",
    "    density = gaussian_kde(ranks)\n",
    "    xs = np.linspace(0,243,243)\n",
    "    density.covariance_factor= lambda : 0.25\n",
    "    density._compute_covariance()\n",
    "\n",
    "    #empirical cumulative distribution function:\n",
    "    ecdf = [(ranks<i).sum()/len(ranks) for i in range(0, 243)]\n",
    "\n",
    "    return mean, median, density(xs), ecdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, med, kde, ecdf = plot_ranks(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "fig, ax = plt.subplots(2,2)\n",
    "gs = GridSpec(2, 2, width_ratios=[[6,2],[6,2]])\n",
    "for i in range(4):\n",
    "    ax[i][j].set_position(gs[i].get_position(fig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(ecdf)\n",
    "plt.plot(kde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_opt_pars(filename):\n",
    "    f = open('../hyperparmeter_optimization/'+filename, 'r')\n",
    "    record=False\n",
    "    for line in f:\n",
    "        if 'Paramaters:' in line:\n",
    "            return [float(i) for i in line.strip('\\n').replace('[', '').replace(']', '').replace(',', '').split()[1:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = find_opt_pars('hpo_implicit_bpr.dat')\n",
    "pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_implicit_bpr(pars, inp):\n",
    "    model = implicit.bpr.BayesianPersonalizedRanking(factors=int(pars[0]),\n",
    "                                                 learning_rate=pars[1],\n",
    "                                                 regularization=pars[2],\n",
    "                                                 iterations=int(pars[3]),\n",
    "                                                 use_gpu=False)\n",
    "    model.fit(sparse.csr_matrix(inp), show_progress=False)\n",
    "    return np.dot(model.item_factors, model.user_factors.T)\n",
    "\n",
    "\n",
    "pars = find_opt_pars('hpo_implicit_bpr.dat')\n",
    "implicit_bpr_preds = train_implicit_bpr(pars, train)\n",
    "for _ in range(7):\n",
    "    implicit_bpr_preds += train_implicit_bpr(pars, train)\n",
    "implicit_bpr_ranks = utils.evaluate_predictions(implicit_bpr_preds, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_implicit_als(pars, inp):\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=params['factors'],\n",
    "                                                 regularization=params['regularization'],\n",
    "                                                 iterations=params['iterations'],\n",
    "                                                 num_threads=1,\n",
    "                                                 use_gpu=False)\n",
    "    model.fit(train)\n",
    "    return np.dot(model.item_factors, model.user_factors.T)\n",
    "        #evaluate by calculating mean rank:\n",
    "        results.append(utils.evaluate_predictions(pred_matrix, test).mean())\n",
    "\n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "means = list()\n",
    "medians = list()\n",
    "kdes = list()\n",
    "\n",
    "model = implicit.bpr.BayesianPersonalizedRanking(factors=337,\n",
    "                                                learning_rate=0.06276,\n",
    "                                                regularization=0.001147,\n",
    "                                                iterations=25,\n",
    "                                                use_gpu=False)\n",
    "model.fit(train)\n",
    "\n",
    "imbpr_preds = np.dot(model.item_factors, model.user_factors.T)\n",
    "ranks = utils.evaluate_predictions(imbpr_preds, test)\n",
    "m, med, kde = plot_ranks(ranks)\n",
    "means.append(m)\n",
    "medians.append(med)\n",
    "kdes.append(kde)\n",
    "\n",
    "for _ in range(5):\n",
    "    model = implicit.bpr.BayesianPersonalizedRanking(factors=337,\n",
    "                                                learning_rate=0.06276,\n",
    "                                                regularization=0.001147,\n",
    "                                                iterations=25,\n",
    "                                                use_gpu=False)\n",
    "    model.fit(train)\n",
    "\n",
    "    imbpr_preds += np.dot(model.item_factors, model.user_factors.T)\n",
    "    ranks = utils.evaluate_predictions(imbpr_preds, test)\n",
    "    m, med, kde = plot_ranks(ranks)\n",
    "    means.append(m)\n",
    "    medians.append(med)\n",
    "    kdes.append(kde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    model = implicit.bpr.BayesianPersonalizedRanking(factors=337,\n",
    "                                                learning_rate=0.06276,\n",
    "                                                regularization=0.001147,\n",
    "                                                iterations=25,\n",
    "                                                use_gpu=False)\n",
    "    model.fit(train)\n",
    "\n",
    "    imbpr_preds += np.dot(model.item_factors, model.user_factors.T)\n",
    "    ranks = utils.evaluate_predictions(imbpr_preds, test)\n",
    "    m, med, kde = plot_ranks(ranks)\n",
    "    means.append(m)\n",
    "    medians.append(med)\n",
    "    kdes.append(kde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in kdes:\n",
    "    plt.plot(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(medians)),medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightfm\n",
    "means2 =list()\n",
    "medians2=list()\n",
    "kdes2=list()\n",
    "\n",
    "##LightFM:                                                                                                                                                                     \n",
    "#lightfm 'user id' (chemical id)                                                                                                                                               \n",
    "cid = np.arange(train.shape[0])\n",
    "#lightfm 'item id' (target id)                                                                                                                                                 \n",
    "tid = np.arange(train.shape[1])\n",
    "model = lightfm.LightFM(no_components = 127,\n",
    "                           loss='warp',\n",
    "                           max_sampled=9,\n",
    "                           learning_rate=0.056129688436596194)\n",
    "model.fit(sparse.csr_matrix(train), epochs=6)\n",
    "lfm_prediction_matrix = model.predict(np.repeat(cid, len(tid)), np.tile(tid, len(cid)))\n",
    "lfm_prediction_matrix = np.reshape(lfm_prediction_matrix, (len(cid), len(tid)))\n",
    "\n",
    "ranks = utils.evaluate_predictions(lfm_prediction_matrix, test)\n",
    "m, med, kde = plot_ranks(ranks)\n",
    "means2.append(m)\n",
    "medians2.append(med)\n",
    "kdes2.append(kde)\n",
    "\n",
    "for _ in range(10):\n",
    "    print(_)\n",
    "    model = lightfm.LightFM(no_components = 127,\n",
    "                           loss='warp',\n",
    "                           max_sampled=9,\n",
    "                           learning_rate=0.056129688436596194)\n",
    "    model.fit(sparse.csr_matrix(train), epochs=6)\n",
    "\n",
    "    temp = model.predict(np.repeat(cid, len(tid)), np.tile(tid, len(cid)))\n",
    "    lfm_prediction_matrix+=np.reshape(temp, (len(cid), len(tid)))\n",
    "    \n",
    "    ranks = utils.evaluate_predictions(lfm_prediction_matrix, test)\n",
    "    m, med, kde = plot_ranks(ranks)\n",
    "    means2.append(m)\n",
    "    medians2.append(med)\n",
    "    kdes2.append(kde)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(means2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(medians2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in kdes2:\n",
    "    plt.plot(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks1 = utils.evaluate_predictions(imbpr_preds, test)\n",
    "ranks2 = utils.evaluate_predictions(lfm_prediction_matrix, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ranks1, ranks2, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import rankdata\n",
    "one = rankdata(-imbpr_preds[:,0])\n",
    "two = rankdata(-lfm_prediction_matrix[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(one, two, alpha=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(one)\n",
    "\n",
    "plt.scatter(three[indices][:10000], one[indices][:10000], alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "model = sm.OLS(one[indices][:10000], two[indices][:10000])\n",
    "results = model.fit()f\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdeplot(one,two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict label scores using label correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##This version uses sparse matrices, which keeps everything low\n",
    "##memory. But it's a bit slower because getting/setting sparse objects is in general\n",
    "##slower than numpy. \n",
    "def makeCorrelations(y_in):\n",
    "    assert isinstance(y_in, sparse.csr_matrix)\n",
    "    tot_instances = np.array(y_in.sum(axis=0))[0]\n",
    "    L = sparse.lil_matrix((y_in.shape[1], y_in.shape[1]))\n",
    "\n",
    "    for idx in tqdm_notebook(range(y_in.shape[0]), smoothing=0.1):\n",
    "        row = y_in[idx]\n",
    "        if row.sum()>1:\n",
    "            for j,k in itertools.permutations(row.nonzero()[1], 2):\n",
    "                L[j,k] += (1)/(tot_instances[k])             \n",
    "    return L\n",
    "\n",
    "##This calculates predicted probabilities for labels (1's in the train matrix are preserved as 1's)\n",
    "def makePredictions(y_in, L):\n",
    "    L1 = 1-L.toarray() #working with dense array is much easier for this. \n",
    "                    #but because it's only numLabels x numLabels it's not that big.\n",
    "    y_new = y_in.toarray().astype('float32') #working with a dense array again\n",
    "                                             #for ease of row-wise, elementwise addition \n",
    "    for count, row in tqdm_notebook(enumerate(y_in), total=y_in.shape[0], smoothing=0.1):\n",
    "        posLines = row.nonzero()[1]\n",
    "        corrs = L1[:,posLines]\n",
    "        probs = 1-np.prod(corrs, axis=1)\n",
    "        y_new[count]+=probs #elementwise addition here. \n",
    "        y_new[count] = np.clip(y_new[count], 0, 1)\n",
    "    return sparse.csr_matrix(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = makeCorrelations(train)\n",
    "lc_preds = makePredictions(train, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three = rankdata(-lc_preds.toarray()[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(one, three, alpha=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(two, three, alpha=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bap = [1,2]\n",
    "stdevs =list()\n",
    "stdevs.append(np.std(bap))\n",
    "for _ in range(100):\n",
    "    bap.append(2)\n",
    "    stdevs.append(np.std(bap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stdevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bapbap(predictions, test):\n",
    "    #if isinstance(test, sparse.csr_matrix):\n",
    "    #    test = test.toarray()\n",
    "\n",
    "    #This will mask all ROWS that contain no test ligands. No point ranking\n",
    "    #a row if you're aren't going to evaluate the ranks!\n",
    "    #(and it works on sparse or np.array)\n",
    "    row_mask = np.array(test.sum(axis=1)>0).reshape(-1,)\n",
    "    test_masked = test[row_mask]\n",
    "    get_ranks = test_masked.astype(bool)\n",
    "    prediction_ranks = rankdata(-predictions[row_mask], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranks_masked():\n",
    "    predictions = copy.copy(lc_preds)\n",
    "    if isinstance(predictions, sparse.csr_matrix):\n",
    "        predictions = predictions.toarray()\n",
    "        \n",
    "    row_mask = np.array(test.sum(axis=1)>0).reshape(-1,)\n",
    "    test_masked = test[row_mask]\n",
    "    get_ranks = test_masked.astype(bool)\n",
    "    predictions2 = np.ma.masked_array(predictions[row_mask], mask=train.toarray()[row_mask].astype(bool))    \n",
    "    prediction_ranks = rankdata(-predictions2, axis=1)\n",
    "    return prediction_ranks[get_ranks.toarray()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranks_unmasked():\n",
    "    predictions = copy.copy(lc_preds)\n",
    "    if isinstance(predictions, sparse.csr_matrix):\n",
    "        predictions = predictions.toarray()\n",
    "        \n",
    "    row_mask = np.array(test.sum(axis=1)>0).reshape(-1,)\n",
    "    test_masked = test[row_mask]\n",
    "    get_ranks = test_masked.astype(bool)\n",
    "    #predictions2 = np.ma.masked_array(predictions[row_mask], mask=train.toarray()[row_mask].astype(bool))    \n",
    "    prediction_ranks = rankdata(-predictions[row_mask], axis=1)\n",
    "    return prediction_ranks[get_ranks.toarray()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_masked = get_ranks_masked()\n",
    "r_unmasked = get_ranks_unmasked()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdeplot(r_masked)\n",
    "kdeplot(r_unmasked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_unmasked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = copy.copy(lc_preds)\n",
    "\n",
    "\n",
    "\n",
    "if isinstance(predictions, sparse.csr_matrix):\n",
    "\tpredictions = predictions.toarray()\n",
    "\n",
    "#predictions = np.ma.masked_array(predictions, mask=train.toarray()[row_mask].astype(bool))    \n",
    "    \n",
    "from scipy.stats.mstats import rankdata\n",
    "row_mask = np.array(test.sum(axis=1)>0).reshape(-1,)\n",
    "\n",
    "test_masked = test[row_mask]\n",
    "get_ranks = test_masked.astype(bool)\n",
    "\n",
    "predictions2 = np.ma.masked_array(predictions[row_mask], mask=train.toarray()[row_mask].astype(bool))    \n",
    "prediction_ranks = rankdata(-predictions2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdeplot(prediction_ranks[get_ranks.toarray()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ranks.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict label scores using implicit BPR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "model = implicit.bpr.BayesianPersonalizedRanking(factors=337,\n",
    "                                                learning_rate=0.06276,\n",
    "                                                regularization=0.001147,\n",
    "                                                iterations=25,\n",
    "                                                use_gpu=False)\n",
    "model.fit(train)\n",
    "\n",
    "imbpr_preds = np.dot(model.item_factors, model.user_factors.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_mean_rank(preds, test):\n",
    "    t = test.toarray().astype(bool)\n",
    "    #order from highest to lowest:\n",
    "    order = (-preds).argsort(axis=1)\n",
    "    #get ranks of each ligand.\n",
    "    ranks = order.argsort(axis=1)\n",
    "    return ranks[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_ranks = return_mean_rank(lc_preds.toarray(), test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbpr_ranks = return_mean_rank(imbpr_preds, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "kdeplot(lc_ranks, label='Label correlation', cumulative=True)\n",
    "kdeplot(imbpr_ranks, label='ImplicitBPR', cumulative=True)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions import ECDF\n",
    "ecdf = ECDF(lc_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lc_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "ecdf = ECDF(lc_ranks)\n",
    "plt.plot(ecdf.x, ecdf.y, label='Label correlation')\n",
    "ecdf = ECDF(imbpr_ranks)\n",
    "plt.plot(ecdf.x, ecdf.y, label='ImplicitBPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "#bal = [(test_ranks<i).sum()/len(test_ranks) for i in range(0, 20)]\n",
    "plt.plot([(lc_ranks<i).sum()/len(lc_ranks) for i in range(0, 256)])\n",
    "plt.plot([(imbpr_ranks<i).sum()/len(imbpr_ranks) for i in range(0, 256)])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([(imbpr_ranks<i).sum()/len(imbpr_ranks) for i in range(0, 256)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([(lc_ranks<i).sum()/len(imbpr_ranks) for i in range(0, 256)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(pa))\n",
    "print(np.median(wa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order from highest to lowest:\n",
    "order2 = (-pred_matrix2).argsort(axis=1)\n",
    "#get ranks of each ligand.\n",
    "ranks2 = order2.argsort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order from highest to lowest:\n",
    "order2 = (-pred_matrix2).argsort(axis=1)\n",
    "#get ranks of each ligand.\n",
    "ranks2 = order2.argsort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kdeplot(ranks2[test.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM, datasets\n",
    "data = datasets.fetch_movielens()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ranks2[test.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kdeplot(ranks[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##new version, reporting the average rank of test ligands.\n",
    "#order from highest to lowest:\n",
    "order = (-prediction_matrix).argsort()\n",
    "#get ranks of each ligand. \n",
    "ranks = order.argsort()\n",
    "    \n",
    "#calc rank fo each ligand\n",
    "#test2 = np.array(test.todense())\n",
    "test_ranks = ranks[row_mask][np.array(test[row_mask], dtype=bool)]\n",
    "\n",
    "plt.plot(test_ranks, linewidth=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [(test_ranks<i).sum()/len(test_ranks) for i in range(0, 20)]\n",
    "plt.plot(ranks)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.toarray().astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightfm\n",
    "##LightFM:                                                                                                                                                                     \n",
    "#lightfm 'user id' (chemical id)                                                                                                                                               \n",
    "cid = np.arange(train.shape[0])\n",
    "#lightfm 'item id' (target id)                                                                                                                                                 \n",
    "tid = np.arange(train.shape[1])\n",
    "model = lightfm.LightFM(no_components = 127,\n",
    "                           loss='warp',\n",
    "                           max_sampled=9,\n",
    "                           learning_rate=0.056129688436596194)\n",
    "model.fit(sparse.csr_matrix(train), epochs=6)\n",
    "lfm_prediction_matrix = model.predict(np.repeat(cid, len(tid)), np.tile(tid, len(cid)))\n",
    "lfm_prediction_matrix = np.reshape(lfm_prediction_matrix, (len(cid), len(tid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_lc = (-lc_prediction_matrix).argsort()\n",
    "#get ranks of each ligand. \n",
    "ranks_lc = order_lc.argsort()\n",
    "\n",
    "order_im = (-im_prediction_matrix).argsort()\n",
    "#get ranks of each ligand. \n",
    "ranks_im = order_im.argsort()\n",
    "\n",
    "order_lfm = (-lfm_prediction_matrix).argsort()\n",
    "#get ranks of each ligand. \n",
    "ranks_lfm = order_lfm.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inverse_ranks_lc = 1/(order_lc.argsort()+1)\n",
    "inverse_ranks_im = 1/(order_im.argsort()+1)\n",
    "inverse_ranks_lfm = 1/(order_lfm.argsort()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_combined = inverse_ranks_lc+inverse_ranks_im+inverse_ranks_lfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_com = (-inverse_combined).argsort()\n",
    "#get ranks of each ligand. \n",
    "ranks_com = order_com.argsort()\n",
    "print(np.mean(ranks_com[np.array(test, dtype=bool)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ranks = (ranks_lc+ranks_im)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(ranks_lc[np.array(test, dtype=bool)]))\n",
    "\n",
    "print(np.mean(ranks_im[np.array(test, dtype=bool)]))\n",
    "\n",
    "print(np.mean(avg_ranks[np.array(test, dtype=bool)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##new version, reporting the average rank of test ligands.\n",
    "#order from highest to lowest:\n",
    "order = (-prediction_matrix).argsort()\n",
    "#get ranks of each ligand. \n",
    "ranks = order.argsort()\n",
    "    \n",
    "#calc rank fo each ligand\n",
    "#test2 = np.array(test.todense())\n",
    "test_ranks = ranks[row_mask][np.array(test[row_mask], dtype=bool)]\n",
    "\n",
    "plt.plot(test_ranks, linewidth=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(test_ranks))\n",
    "print(np.median(test_ranks))\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "density = gaussian_kde(test_ranks)\n",
    "xs = np.linspace(0,243, 300)\n",
    "density.covariance_factor = lambda : 0.25\n",
    "density._compute_covariance()\n",
    "plt.plot(xs,density(xs))\n",
    "plt.axhline(0, c='k')\n",
    "#plt.xlim(-0.5,150)\n",
    "plt.scatter(test_ranks, np.zeros(len(test_ranks))+np.random.uniform(-0.02,0.0, len(test_ranks)), alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [(test_ranks<i).sum()/len(test_ranks) for i in range(0, 20)]\n",
    "plt.plot(ranks)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###load data:\n",
    "#train, test = utils.load_time_split()\n",
    "\n",
    "filenames = ['hpo_implicit_als.dat', 'hpo_implicit_bpr.dat',\n",
    "             'hpo_lightfm_warp.dat', 'hpo_lightfm_bpr.dat']\n",
    "def find_opt_pars(filename):\n",
    "    f = open('../hyperparmeter_optimization/'+filename, 'r')\n",
    "    record=False\n",
    "    for line in f:\n",
    "        if 'Paramaters:' in line:\n",
    "            return [float(i) for i in line.strip('\\n').replace('[', '').replace(']', '').replace(',', '').split()[1:]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_implicit_als(pars):\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=int(pars[0]),\n",
    "                                                     regularization=pars[1],\n",
    "                                                     iterations=int(pars[2]),\n",
    "                                                     num_threads=1,\n",
    "                                                     use_gpu=False)\n",
    "    model.fit(sparse.csr_matrix(train))\n",
    "    prediction_matrix=np.dot(model.item_factors, model.user_factors.T)\n",
    "    test_ranks = utils.evaluate_predictions(prediction_matrix, sparse.csr_matrix(test),avg=False)\n",
    "    return np.mean(test_ranks), np.median(test_ranks)\n",
    "\n",
    "def train_implicit_bpr(pars):\n",
    "    model = implicit.bpr.BayesianPersonalizedRanking(factors=int(pars[0]),\n",
    "                                                 learning_rate=pars[1],\n",
    "                                                 regularization=pars[2],\n",
    "                                                 iterations=int(pars[3]),\n",
    "                                                 use_gpu=False)\n",
    "\n",
    "    model.fit(sparse.csr_matrix(train))\n",
    "    prediction_matrix=np.dot(model.item_factors, model.user_factors.T)\n",
    "    #test_ranks = utils.evaluate_predictions(prediction_matrix, sparse.csr_matrix(test),avg=False)\n",
    "    return np.mean(test_ranks), np.median(test_ranks)\n",
    "\n",
    "\n",
    "\n",
    "##LightFM:\n",
    "#lightfm 'user id' (chemical id)\n",
    "cid = np.arange(train.shape[0])\n",
    "#lightfm 'item id' (target id)\n",
    "tid = np.arange(train.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "def train_lightfm_warp(pars):\n",
    "    model = lightfm.LightFM(no_components = int(pars[0]),\n",
    "                           loss='warp',\n",
    "                           max_sampled=int(pars[1]),\n",
    "                           learning_rate=pars[2])\n",
    "    model.fit(sparse.csr_matrix(train), epochs=int(pars[3]))\n",
    "    prediction_matrix = model.predict(np.repeat(cid, len(tid)), np.tile(tid, len(cid)))\n",
    "    prediction_matrix = np.reshape(prediction_matrix, (len(cid), len(tid)))\n",
    "    test_ranks = utils.evaluate_predictions(prediction_matrix, sparse.csr_matrix(test),avg=False)\n",
    "    return np.mean(test_ranks), np.median(test_ranks)\n",
    "\n",
    "def train_lightfm_bpr(pars):\n",
    "    model = lightfm.LightFM(no_components = int(pars[0]),\n",
    "                           loss='bpr',\n",
    "                           max_sampled=int(pars[1]),\n",
    "                           learning_rate=pars[2])\n",
    "    model.fit(sparse.csr_matrix(train), epochs=int(pars[3]))\n",
    "    prediction_matrix = model.predict(np.repeat(cid, len(tid)), np.tile(tid, len(cid)))\n",
    "    prediction_matrix = np.reshape(prediction_matrix, (len(cid), len(tid)))\n",
    "    test_ranks = utils.evaluate_predictions(prediction_matrix, sparse.csr_matrix(test),avg=False)\n",
    "    return np.mean(test_ranks), np.median(test_ranks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_implicit_bpr(pars):\n",
    "    model = implicit.bpr.BayesianPersonalizedRanking(factors=int(pars[0]),\n",
    "                                                 learning_rate=pars[1],\n",
    "                                                 regularization=pars[2],\n",
    "                                                 iterations=int(pars[3]),\n",
    "                                                 use_gpu=False)\n",
    "\n",
    "    model.fit(train)\n",
    "    prediction_matrix=np.dot(model.item_factors, model.user_factors.T)\n",
    "    #test_ranks = utils.evaluate_predictions(prediction_matrix, sparse.csr_matrix(test),avg=False)\n",
    "    return prediction_matrix\n",
    "\n",
    "def score_prediction_matrix(preds, test):\n",
    "    t = test.toarray().astype(bool)\n",
    "    #order from highest to lowest:\n",
    "    order = (-preds).argsort(axis=1)\n",
    "    #get ranks of each ligand.\n",
    "    ranks = order.argsort(axis=1)\n",
    "    return ranks[t]\n",
    "\n",
    "#bpr:\n",
    "pars = find_opt_pars(filenames[1])\n",
    "preds = train_implicit_bpr(pars)\n",
    "r = score_prediction_matrix(preds, test)\n",
    "\n",
    "mean = np.mean(r)\n",
    "print(mean)\n",
    "median = np.median(r)\n",
    "print(median)\n",
    "#ecdf = [(r<i).sum()/len(r) for i in range(0, 243)]\n",
    "\n",
    "for _ in range(16):\n",
    "    preds += train_implicit_bpr(pars)\n",
    "    r = score_prediction_matrix(preds, test)\n",
    "    mean = np.mean(r)\n",
    "    print(mean)\n",
    "    median = np.median(r)\n",
    "    print(median)\n",
    "\n",
    "\n",
    "#    outfile.write(filenames[1]+': '+str(mean)+' '+str(median)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds\n",
    "t = test.toarray().astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order from highest to lowest:\n",
    "order = (-lc_preds.toarray()).argsort(axis=1)\n",
    "#get ranks of each ligand.\n",
    "ranks = order.argsort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j,k in zip(*test.toarray().nonzero()):\n",
    "    value = lc_preds[j,k]\n",
    "    if value==0:\n",
    "        one = (-lc_preds.toarray()[j]).argsort()\n",
    "        two = one.argsort()\n",
    "        print('Found a zero, is is rank:',two[k])\n",
    "    print(j,k, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[4,2,7,2,1],[1,2,3,4,5]])\n",
    "rank = a.argsort(axis=1).argsort(axis=1)\n",
    "\n",
    "unique, inverse = np.unique(a, return_inverse = True, axis=0)\n",
    "\n",
    "unique_rank_sum = np.zeros_like(unique)\n",
    "np.add.at(unique_rank_sum, inverse, rank)\n",
    "unique_count = np.zeros_like(unique)\n",
    "np.add.at(unique_count, inverse, 1)\n",
    "\n",
    "unique_rank_mean = unique_rank_sum.astype(np.float) / unique_count\n",
    "\n",
    "rank_mean = unique_rank_mean[inverse]\n",
    "\n",
    "rank_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, inverse = np.unique(a, return_inverse = True, axis=1)\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rank_sum = np.zeros_like(unique)\n",
    "np.add.at(unique_rank_sum, inverse, rank)\n",
    "unique_rank_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-lc_preds.toarray()[0][227])\n",
    "one = (-lc_preds.toarray()[0]).argsort()\n",
    "two = one.argsort()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two[(-lc_preds.toarray()[0]==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter((-lc_preds.toarray()[0]).argsort(), (-lc_preds.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "\n",
    "plt.scatter(rankdata(-lc_preds.toarray()[0]), (-lc_preds.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import rankdata\n",
    "rankdata(-lc_preds.toarray()[:13000], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = np.array(test.sum(axis=1)>0).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "rm_ranked = rankdata(-lc_preds.toarray()[rm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trm = test.toarray()[rm].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.toarray()[rm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bapbap(predictions, test):\n",
    "    \n",
    "    row_mask = np.array(test.sum(axis=1)>0).reshape(-1,)\n",
    "    test_masked = test[row_mask]\n",
    "    get_ranks = test_masked.toarray().astype(bool) #this will select using boolean all test ranks.\n",
    "\n",
    "    #rankdata approach, which correctly handles ties:\n",
    "    prediction_ranks = rankdata(-predictions[row_mask], axis=1)\n",
    "\n",
    "    #all ranks:\n",
    "    prediction_ranks[get_ranks]\n",
    "    return prediction_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_mask = np.array(test.sum(axis=1)>0).reshape(-1,)\n",
    "row_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_masked = test[row_mask]\n",
    "test_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ranks = test_masked.toarray().astype(bool)\n",
    "get_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-lc_preds[row_mask].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_ranks = rankdata(-lc_preds[row_mask].toarray(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_ranks = prediction_ranks[get_ranks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdeplot(all_test_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(rm_ranked[trm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankdata(-lc_preds.toarray()[0])[lc_preds.toarray()[0]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import rankdata\n",
    "plt.scatter(rankdata(-lc_preds.toarray()[0]), (-lc_preds.toarray()[0]), alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j,k in zip(ranks, t):\n",
    "    if sum(k)!=0:\n",
    "        v = np.mean(j[k])\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0][t[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = score_prediction_matrix(preds, test)\n",
    "pr = score_prediction_matrix(lc_preds.toarray(), test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = rm_ranked[trm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "mean = np.mean(r)\n",
    "print(mean)\n",
    "median = np.median(r)\n",
    "print(median)\n",
    "ecdf = [(r<i).sum()/len(r) for i in range(0, 243)]\n",
    "plt.plot(ecdf, label='ImplicitBPR')\n",
    "\n",
    "\n",
    "\n",
    "pr = score_prediction_matrix(lc_preds.toarray(), test)\n",
    "mean = np.mean(pr)\n",
    "print(mean)\n",
    "median = np.median(pr)\n",
    "print(median)\n",
    "ecdf = [(pr<i).sum()/len(pr) for i in range(0, 243)]\n",
    "plt.plot(ecdf, label='LabelCorr')\n",
    "\n",
    "\n",
    "pr = rm_ranked[trm]\n",
    "mean = np.mean(pr)\n",
    "print(mean)\n",
    "median = np.median(pr)\n",
    "print(median)\n",
    "ecdf = [(pr<i).sum()/len(pr) for i in range(0, 243)]\n",
    "plt.plot(ecdf, label='LabelCorr.Avg')\n",
    "\n",
    "plt.legend()\n",
    "##plt.ylim(0,20)\n",
    "plt.xlim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(lc_ranks)\n",
    "print(mean)\n",
    "median = np.median(lc_ranks)\n",
    "print(median)\n",
    "ecdf = [(lc_ranks<i).sum()/len(lc_ranks) for i in range(0, 243)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ecdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kdeplot(lc_ranks)\n",
    "kdeplot(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outfile = open('results.dat', 'w')\n",
    "#outfile.write('algorithm, mean, median\\n')\n",
    "\n",
    "##implicit:\n",
    "#als:\n",
    "pars = find_opt_pars(filenames[0])\n",
    "for _ in range(3):\n",
    "    mean, median = train_implicit_als(pars)\n",
    "    #outfile.write(filenames[0]+': '+str(mean)+' '+str(median)+'\\n')\n",
    "\n",
    "#bpr:\n",
    "pars = find_opt_pars(filenames[1])\n",
    "for _ in range(3):\n",
    "    mean, median = train_implicit_bpr(pars)\n",
    "    outfile.write(filenames[1]+': '+str(mean)+' '+str(median)+'\\n')\n",
    "\n",
    "##lightfm\n",
    "#warp\n",
    "pars = find_opt_pars(filenames[2])\n",
    "for _ in range(3):\n",
    "    mean, median = train_lightfm_warp(pars)\n",
    "    outfile.write(filenames[2]+': '+str(mean)+' '+str(median)+'\\n')\n",
    "\n",
    "#bpr\n",
    "pars = find_opt_pars(filenames[3])\n",
    "for _ in range(3):\n",
    "    mean, median = train_lightfm_bpr(pars)\n",
    "    outfile.write(filenames[3]+': '+str(mean)+' '+str(median)+'\\n')\n",
    "\n",
    "#label correlation:\n",
    "L1 = 1- utils.makeCorrelations(train)\n",
    "prediction_matrix = utils.makeProbabilities(train, L1)\n",
    "test_ranks = utils.evaluate_predictions(prediction_matrix, sparse.csr_matrix(test), avg=False)\n",
    "outfile.write('label correl: '+str(np.mean(test_ranks))+' '+str(np.median(test_ranks))+'\\n')\n",
    "\n",
    "\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
