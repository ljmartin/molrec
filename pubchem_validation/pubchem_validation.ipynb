{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubChem validation\n",
    "This notebook demonstrates a new (?) idea in LBVS validation - pinging the pubchem server for assays for a given compound / target pair, and assessing the Outcome field. \n",
    "\n",
    "The main difficulty/novelty here is automating the approach while ensuring it gets the CORRECT assay. This is because many targets have different names, and there is no standard format for assay descriptions *or* outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmar3213/miniconda3/envs/lew_conda/lib/python3.7/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "from scipy import stats\n",
    "\n",
    "import pubchempy as pcp\n",
    "from chembl_webresource_client.new_client import new_client \n",
    "import json\n",
    "import requests\n",
    "\n",
    "import copy\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make some structure-predictions with label correlations:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all labels:\n",
    "interaction_matrix = sparse.load_npz('../data/interaction_matrix_pchembl.npz')\n",
    "smiles = pd.read_csv('../data/pchembl_chemicals.csv')\n",
    "targets_df= pd.read_csv('../data/subset_targets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 189/85681 [00:00<00:45, 1884.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_in shape is: (337951, 243)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85681/85681 [00:27<00:00, 3131.83it/s]\n",
      "100%|██████████| 337951/337951 [00:59<00:00, 5685.07it/s]\n"
     ]
    }
   ],
   "source": [
    "probability_matrix = utils.train_label_correlation(interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, fps = utils.load_time_split(year=2030, \n",
    "                                         return_fingerprints=True) #set a year after now to get ALL records\n",
    "\n",
    "probability_arr = probability_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be a high number < 1:\n",
      "0.99991256\n",
      "Should be a low number >= 0:\n",
      "0.0\n",
      "Sorted array indices:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[328242,    138],\n",
       "       [ 68104,    138],\n",
       "       [315225,     72],\n",
       "       ...,\n",
       "       [132327,     26],\n",
       "       [132327,     28],\n",
       "       [337950,    242]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sort the predictions in order of probability, highest first. \n",
    "\n",
    "arr = probability_matrix.toarray()\n",
    "arr = arr - interaction_matrix\n",
    "arr_sorted = np.dstack(np.unravel_index(np.argsort(-arr.ravel()), (arr.shape[0], arr.shape[1])))[0]\n",
    "print('Should be a high number < 1:')\n",
    "print(probability_arr[arr_sorted[0][0]][arr_sorted[0][1]])\n",
    "print('Should be a low number >= 0:')\n",
    "print(probability_arr[arr_sorted[-1][0]][arr_sorted[-1][1]])\n",
    "print('Sorted array indices:')\n",
    "arr_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C[C@@H](Oc... Vascular endothelial growth factor receptor 2 \t Vascular endothelial growth factor receptor 2\n",
      "CHEMBL601719 C[C@@H](Oc1cc(cnc1N)c2cnn(c2)C3CCNCC3)c4c(Cl)ccc(F)c4Cl\n",
      "Nc1ncnc2sc... Vascular endothelial growth factor receptor 2 \t Vascular endothelial growth factor receptor 2\n",
      "CHEMBL1998585 Nc1ncnc2scc(c3ccc(NC(=O)Nc4cc(ccc4F)C(F)(F)F)cc3)c12\n",
      "CCN(CC)CCN... Serine/threonine-protein kinase PIM1 \t Serine/threonine-protein kinase PIM1\n",
      "CHEMBL535 CCN(CC)CCNC(=O)c1c(C)[nH]c(\\C=C\\2/C(=O)Nc3ccc(F)cc23)c1C\n",
      "CNC(=O)c1c... Vascular endothelial growth factor receptor 2 \t Vascular endothelial growth factor receptor 2\n",
      "CHEMBL2005631 CNC(=O)c1cnc(N)c2c(csc12)c3ccc(NC(=O)Nc4cc(C)ccc4F)cc3\n",
      "Cn1cc(cn1)... Vascular endothelial growth factor receptor 2 \t Vascular endothelial growth factor receptor 2\n",
      "CHEMBL1988717 Cn1cc(cn1)c2cnn3c(N)c(cnc23)c4ccc(NC(=O)Nc5cccc(c5)C(F)(F)F)cc4\n",
      "Cc1ccc(NC(... Vascular endothelial growth factor receptor 2 \t Vascular endothelial growth factor receptor 2\n",
      "CHEMBL2000335 Cc1ccc(NC(=O)Nc2ccc(cc2)c3csc4ncnc(N)c34)cc1C\n",
      "Fc1cccc(c1... Serine/threonine-protein kinase PIM1 \t Serine/threonine-protein kinase PIM1\n",
      "CHEMBL2003638 Fc1cccc(c1)C(=O)Nc2n[nH]c3ccc(cc23)c4cn(Cc5ccccc5)nn4\n",
      "CCCC(=O)Nc... Serine/threonine-protein kinase PIM1 \t Serine/threonine-protein kinase PIM1\n",
      "CHEMBL2005936 CCCC(=O)Nc1n[nH]c2ccc(cc12)c3nnn(Cc4ccccc4)c3c5ccccc5\n",
      "NCCCn1cc(c... Serine/threonine-protein kinase PIM1 \t Serine/threonine-protein kinase PIM1\n",
      "CHEMBL592030 NCCCn1cc(c2cc(c3cc4ccccc4s3)c5[nH]ncc5c2)c6nc(N)ncc16\n",
      "COc1ccc(cc... Serine/threonine-protein kinase PIM1 \t Serine/threonine-protein kinase PIM1\n",
      "CHEMBL1190711 COc1ccc(cc1OC)c2cc3nccn3c(Nc4ncccc4C(=O)N)n2\n"
     ]
    }
   ],
   "source": [
    "#sanity check - make sure the ligand IDX, smiles, and target IDX and target names line up:\n",
    "\n",
    "for pair in arr_sorted[:10]:\n",
    "    smi = smiles['canonical_smiles'].iloc[pair[0]]\n",
    "    chembl_id = smiles['instance_id'].iloc[pair[0]]\n",
    "    predicted_target = targets['pref_name'].iloc[pair[1]]\n",
    "    tid = targets[targets['pref_name']==predicted_target]['pref_name'].iloc[0]\n",
    "    print(smi[:10]+'...', predicted_target, '\\t', tid)\n",
    "    print(chembl_id, smi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure comparisons.\n",
    "\n",
    "An important aspect of this is the knowledge of whether a prediction would have been predicted by nearest-neighbors anyway. These predictions aren't as interesting to us, which is the reason we use a structure-blind approach in the first place. \n",
    "\n",
    "\n",
    "The below functions help calculate jaccard distances in Morgan-space, and also calculate what rank a ligand-target pair would have been if just using the nearest neighbor approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The following is to calculate AVE bias:\n",
    "def fast_jaccard(X, Y=None):\n",
    "    \"\"\"credit: https://stackoverflow.com/questions/32805916/compute-jaccard-distances-on-sparse-matrix\"\"\"\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = sparse.csr_matrix(X)\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    else:\n",
    "        if isinstance(Y, np.ndarray):\n",
    "            Y = sparse.csr_matrix(Y)\n",
    "    assert X.shape[1] == Y.shape[1]\n",
    "\n",
    "    X = X.astype(bool).astype(int)\n",
    "    Y = Y.astype(bool).astype(int)\n",
    "    intersect = X.dot(Y.T)\n",
    "    x_sum = X.sum(axis=1).A1\n",
    "    y_sum = Y.sum(axis=1).A1\n",
    "    xx, yy = np.meshgrid(x_sum, y_sum)\n",
    "    union = ((xx + yy).T - intersect)\n",
    "    return (1 - intersect / union).A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubChem-pinging \n",
    "\n",
    "This became much cleaner when wrapped in a class. The below is a class to perform a number of functions:\n",
    "\n",
    "- save/load checkpoints - i.e. if something breaks, or you want to come back to this later after shutting the laptop, you can save all the data and load it afterwards to pick back up\n",
    "- ping `pubchempy` for compound ID (CID) numbers.\n",
    "- ping `chembl_webresource_client` for target synonyms\n",
    "- ping pubchem REST API for assays associated with a CID\n",
    "- records all of this stuff in dicts to be saved as JSON so I can parse it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class PubChemValidator(object):\n",
    "    def __init__(self, targets_df, interaction_matrix, fps):\n",
    "        self.tdf = targets_df\n",
    "        self.interaction_matrix = interaction_matrix\n",
    "        self.fps = fps\n",
    "\n",
    "        self.ligands = {}\n",
    "        self.targets = {}\n",
    "        self.predictions = {}\n",
    "    \n",
    "    def load_checkpoint(self):\n",
    "        self.ligands = json.load(open('ligands.json', 'r'))\n",
    "        self.targets = json.load(open('targets.json', 'r'))\n",
    "        self.predictions = json.load(open('predictions.json', 'r'))\n",
    "        \n",
    "    def save_checkpoint(self):\n",
    "        with open('ligands.json', 'w') as fp:\n",
    "            json.dump(self.ligands, fp)\n",
    "        with open('targets.json', 'w') as fp:\n",
    "            json.dump(self.ligands, fp)\n",
    "        with open('predictions.json', 'w') as fp:\n",
    "            json.dump(self.predictions, fp)\n",
    "            \n",
    "    def has_ligand(self, idx):\n",
    "        return str(idx) in self.ligands\n",
    "    \n",
    "    def has_target(self, idx):\n",
    "        return str(idx) in self.targets\n",
    "\n",
    "    def has_prediction(self, l_idx, t_idx):\n",
    "        return str(l_idx)+':'+str(t_idx) in self.predictions\n",
    "    \n",
    "    def create_prediction(self, l_idx, t_idx, prob):\n",
    "        record = dict()\n",
    "        record['prob'] = str(prob)\n",
    "        nn = self.get_nnrank_of_target(l_idx, t_idx)\n",
    "        record['nn'] = nn\n",
    "        \n",
    "        self.predictions[str(l_idx)+':'+str(t_idx)] = record\n",
    "        \n",
    "    def create_target(self, idx):\n",
    "        self.targets[str(idx)] = dict()\n",
    "        record = self.targets[str(idx)]\n",
    "    \n",
    "        pref_name = self.tdf['pref_name'].iloc[idx]\n",
    "        tid = self.tdf[self.tdf['pref_name']==pref_name]['chembl_id'].iloc[0]\n",
    "        synonyms = get_synonyms(tid)\n",
    "    \n",
    "        record['pref_name'] = pref_name\n",
    "        record['tid'] = tid\n",
    "        record['synonyms'] = synonyms\n",
    "        \n",
    "    def create_ligand(self, idx):\n",
    "        self.ligands[str(idx)] = dict()\n",
    "        record = self.ligands[str(idx)]\n",
    "    \n",
    "        smi = smiles['canonical_smiles'].iloc[idx]\n",
    "        chemblid = smiles['instance_id'].iloc[idx]\n",
    "        cid = self.get_cid(smi)\n",
    "        assays = self.get_assay_summary(cid)\n",
    "        assays_parsed = self.parse_assays(assays)\n",
    "    \n",
    "        record['smi']=smi\n",
    "        record['chemblid'] = chemblid\n",
    "        record['cid'] = cid\n",
    "        record['assays'] = assays_parsed\n",
    "        \n",
    "    def get_cid(self, smi):\n",
    "        try:\n",
    "            c = pcp.get_compounds(smi, 'smiles')[0]\n",
    "            return c.cid\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return 'cid_failed'\n",
    "        \n",
    "    def get_synonyms(self, tid):\n",
    "        target = new_client.target\n",
    "        res = target.filter(target_chembl_id=tid)\n",
    "        synonyms = [i['component_synonym'] for i in res[0]['target_components'][0]['target_component_synonyms']]\n",
    "        #clean:\n",
    "        synonyms = [self.clean_text(i) for i in target_synonyms]\n",
    "        return synonyms\n",
    "    \n",
    "    def clean_text(self, input_string):\n",
    "        #source: https://stackoverflow.com/questions/34860982/replace-the-punctuation-with-whitespace\n",
    "        #replace these with whitespace:\n",
    "        clean_string = re.sub(r\"\"\"\n",
    "               [(),.;@#?!&$]+  # Accept one or more copies of punctuation\n",
    "               \\ *           # plus zero or more copies of a space,\n",
    "               \"\"\",\n",
    "               \" \",          # and replace it with a single space\n",
    "               input_string.lower(), flags=re.VERBOSE)\n",
    "    \n",
    "        #replace these with nothing:\n",
    "        clean_string = clean_string.replace('-', ' ')\n",
    "        clean_string = clean_string.replace('=', '')\n",
    "        return clean_string\n",
    "\n",
    "    def get_assay_summary(self, cid):\n",
    "        b = json.loads(requests.get('https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/'+str(cid)+'/assaysummary/JSON').content)\n",
    "        return b\n",
    "    \n",
    "    def parse_assays(self, assays):\n",
    "        assays_parsed = []\n",
    "        for assay in assays['Table']['Row']:\n",
    "            cell = assay['Cell']\n",
    "            aid = cell[0]\n",
    "            name = self.clean_text(cell[11])\n",
    "            activity = cell[6]\n",
    "            \n",
    "            assays_parsed.append([aid, activity, name])\n",
    "        return assays_parsed\n",
    "    \n",
    "    def get_nnrank_of_target(self, ligand_idx, target_idx):\n",
    "        \n",
    "        positives = self.interaction_matrix[ligand_idx].nonzero()[1]\n",
    "        all_distances = fast_jaccard(self.fps[ligand_idx], self.fps)[0]\n",
    "        s = np.argsort(all_distances)\n",
    "    \n",
    "        pred = target_idx\n",
    "        curr_rank = 0\n",
    "        count=1\n",
    "        preds = []\n",
    "        seen = []\n",
    "\n",
    "        while pred not in preds:\n",
    "            predictions = self.interaction_matrix[s[count]].nonzero()[1]\n",
    "    \n",
    "            preds = np.setdiff1d(predictions,positives)\n",
    "            preds = np.setdiff1d(preds, seen)\n",
    "            seen += list(preds)\n",
    "            curr_rank += 0 if len(preds)<1 else np.mean(np.arange(len(preds))+1)\n",
    "\n",
    "            count+=1\n",
    "        return curr_rank\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcv = PubChemValidator(targets_df, interaction_matrix, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a random sample of assays across the (many) higher probability ones:\n",
    "n = 400_000\n",
    "take = 20000\n",
    "\n",
    "weight = 1 / (np.arange(n)/take+1)\n",
    "weight = weight/weight.sum()\n",
    "\n",
    "sample = np.random.choice(n, take, p=weight, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[309137     48]\n",
      "[5148   30]\n",
      "[2691   99]\n",
      "[224471     86]\n",
      "[63560   169]\n",
      "[147393    177]\n",
      "[35497   225]\n",
      "[333416     15]\n",
      "[319186    102]\n",
      "[126407     71]\n",
      "[268263    178]\n",
      "[160711     52]\n",
      "[311062    205]\n",
      "[5421   15]\n",
      "[88082    13]\n",
      "[309907     86]\n",
      "[16196   138]\n",
      "[216348     52]\n",
      "[116726     82]\n",
      "[66753   136]\n",
      "[205032    100]\n",
      "[129385     17]\n",
      "[334454     83]\n",
      "[120980    220]\n",
      "[293264     83]\n",
      "[335039    138]\n",
      "[90967   194]\n",
      "[73885   122]\n",
      "[26355   225]\n",
      "[129028    122]\n",
      "[309217    196]\n",
      "[276400    158]\n",
      "[67495    16]\n",
      "[19371    38]\n",
      "[133980    177]\n",
      "[67472   189]\n",
      "[308250     84]\n",
      "[222231    178]\n"
     ]
    }
   ],
   "source": [
    "for count, prediction in enumerate(arr_sorted[sample]):\n",
    "    print(prediction)\n",
    "    ligand_idx = prediction[0]\n",
    "    target_idx = prediction[1]\n",
    "    probability = probability_arr[ligand_idx][target_idx]\n",
    "    \n",
    "    try:\n",
    "        if not pcv.has_ligand(ligand_idx):\n",
    "            pcv.create_ligand(ligand_idx)\n",
    "        \n",
    "        if not pcv.has_target(target_idx):\n",
    "            pcv.create_target(target_idx)\n",
    "        \n",
    "        if not pcv.has_prediction(ligand_idx, target_idx):\n",
    "            pcv.create_prediction(ligand_idx, target_idx, probability)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    if count>0 and count%50==0:\n",
    "        pcv.save_checkpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
